# Performance Benchmarks

SLAF delivers **capability expansion** for single-cell analysis - enabling workflows that are impractical or impossible with traditional tools due to memory constraints and performance limitations.

## **Filtering & Quality Control**

SLAF enables **complex filtering workflows** that would crash traditional tools on larger datasets, while providing **5.3x better memory efficiency**.

### Traditional Approach (Memory-Intensive)

```python
# Load entire dataset into memory
adata = sc.read_h5ad("data.h5ad")  # 7.8 MB for PBMC3K

# Filter cells using pandas boolean indexing
filtered_cells = adata.obs[adata.obs.n_genes_by_counts >= 500]

# Complex filtering with multiple conditions
high_quality = adata.obs[
    (adata.obs.n_genes_by_counts >= 1000) &
    (adata.obs.pct_counts_mt <= 10)
]

# Cluster-based filtering
cluster_cells = adata.obs[adata.obs.leiden.isin(["0", "1", "2"])]
```

### SLAF Approach (Lazy Evaluation)

```python
# Minimal memory footprint
slaf = SLAFArray("data.slaf")

# Direct filtering with SQL optimization
filtered_cells = slaf.filter_cells(n_genes_by_counts=">=500")

# Complex filtering with multiple conditions
high_quality = slaf.filter_cells(
    n_genes_by_counts=">=1000",
    pct_counts_mt="<=10"
)

# Cluster-based filtering
cluster_cells = slaf.filter_cells(leiden=["0", "1", "2"])
```

### Performance Results

| Scenario                | Traditional Total (ms) | SLAF Total (ms) | Total Speedup | Memory Efficiency |
| ----------------------- | ---------------------- | --------------- | ------------- | ----------------- |
| Cells with ‚â•500 genes   | 39.7                   | 9.9             | **4.0x**      | **4.9x**          |
| Cells with ‚â§15% mt      | 22.4                   | 8.5             | **2.6x**      | **4.6x**          |
| Cells in clusters 0,1,2 | 19.6                   | 9.1             | **2.1x**      | **5.0x**          |
| High-quality cells      | 18.5                   | 8.3             | **2.2x**      | **6.1x**          |

**Key Insight**: While individual queries may be slower, SLAF's memory efficiency enables **complex multi-step workflows** that would crash traditional tools on larger datasets.

## **Expression Analysis**

SLAF provides **SQL-native submatrix queries** with **minimal memory footprint**, enabling complex expression analysis without loading entire datasets.

### Traditional Approach (Load Everything)

```python
# Must load entire dataset
adata = sc.read_h5ad("data.h5ad")

# Single-cell expression
cell_id = "AAACCTGAGAAACCAT-1"
cell_idx = adata.obs.index.get_loc(cell_id)
result = adata.X[cell_idx, :]

# Single-gene expression
gene_id = "MS4A1"
gene_idx = adata.var.index.get_loc(gene_id)
result = adata.X[:, gene_idx]

# Submatrix extraction
cell_start, cell_end = 0, 100
gene_start, gene_end = 0, 50
result = adata.X[cell_start:cell_end, gene_start:gene_end]
```

### SLAF Approach (Lazy Submatrix)

```python
# No full dataset loading
slaf = SLAFArray("data.slaf")

# Single-cell expression
result = slaf.get_cell_expression("AAACCTGAGAAACCAT-1")

# Single-gene expression
result = slaf.get_gene_expression("MS4A1")

# Submatrix extraction
result = slaf.get_submatrix(
    cell_range=(0, 100),
    gene_range=(0, 50)
)
```

### Performance Results

| Scenario                 | Traditional Total (ms) | SLAF Total (ms) | Total Speedup | Memory Efficiency |
| ------------------------ | ---------------------- | --------------- | ------------- | ----------------- |
| Single cell expression   | 18.9                   | 10.7            | **1.8x**      | **6.4x**          |
| Two cells                | 18.5                   | 10.6            | **1.7x**      | **6.0x**          |
| Single gene across cells | 21.4                   | 21.5            | 1.0x          | **6.4x**          |
| 100√ó50 submatrix         | 18.4                   | 44.4            | 0.4x          | **6.0x**          |
| 500√ó500 submatrix        | 18.3                   | 52.0            | 0.4x          | **1.2x**          |

**Key Insight**: SLAF's **5.5x memory efficiency** for most queries enables analysis of datasets that don't fit in memory.

## **Lazy Processing**

SLAF's **lazy evaluation** enables **workflow chaining** without memory explosion, making complex preprocessing pipelines practical.

### Traditional Approach (Eager Loading)

```python
# Each step loads data into memory
adata = sc.read_h5ad("data.h5ad")

# QC metrics calculation
sc.pp.calculate_qc_metrics(adata, inplace=True)

# Cell filtering with min_counts and min_genes
sc.pp.filter_cells(adata, min_counts=500, min_genes=200, inplace=True)

# Gene filtering
sc.pp.filter_genes(adata, min_counts=10, min_cells=5, inplace=True)

# Normalization
sc.pp.normalize_total(adata, target_sum=1e4, inplace=True)

# Log transformation
sc.pp.log1p(adata)

# Each operation duplicates data in memory
expression = adata.X[cell_ids, gene_ids]
```

### SLAF Approach (Lazy Chaining)

```python
# Lazy evaluation throughout
adata = LazyAnnData("data.slaf")  # LazyAnnData object

# QC metrics calculation (lazy)
pp.calculate_qc_metrics(adata, inplace=True)

# Cell filtering (lazy)
pp.filter_cells(adata, min_counts=500, min_genes=200, inplace=True)

# Gene filtering (lazy)
pp.filter_genes(adata, min_counts=10, min_cells=5, inplace=True)

# Normalization (lazy)
pp.normalize_total(adata, target_sum=1e4, inplace=True)

# Log transformation (lazy)
pp.log1p(adata)

# Materialize results when needed
expression = adata.X[cell_ids, gene_ids].compute()  # LazyExpressionMatrix.compute()
```

### Performance Results

| Operation                     | Traditional Total (ms) | SLAF Total (ms) | Total Speedup | Memory Efficiency |
| ----------------------------- | ---------------------- | --------------- | ------------- | ----------------- |
| Calculate QC metrics          | 115.4                  | 55.0            | **2.1x**      | **13.3x**         |
| Filter cells (min_counts=500) | 23.6                   | 233.8           | 0.1x          | **1.0x**          |
| Filter genes (min_counts=10)  | 32.7                   | 232.8           | 0.1x          | **1.7x**          |
| Normalize total               | 25.2                   | 419.8           | 0.1x          | **1.7x**          |
| Log1p transformation          | 23.1                   | 208.8           | 0.1x          | **0.6x**          |

**Key Insight**: Lazy evaluation enables **workflow chaining** that would cause memory explosions with traditional tools.

> **Note**: The updated lazy processing benchmarks now measure the time to **execute** lazy operations (including `.compute()` calls), providing realistic performance comparisons. The code examples above show the correct usage with `.compute()` calls to materialize results.

## **ML Training**

SLAF streams cells to training loops at **39M tokens/sec** with **efficient multi-process scaling**, enabling ML training on datasets that don't fit in memory.

### Traditional Approach (Memory Bottleneck)

```python
# Load entire dataset for tokenization
adata = sc.read_h5ad("data.h5ad")

# Manual tokenization in memory
cell_integer_id_range = (0, 2048)
cell_start, cell_end = cell_integer_id_range
max_genes = 2048

token_sequences = []
for cell_idx in range(cell_start, cell_end):
    # Get expression for this cell
    expr_vector = adata.X[cell_idx, :].toarray().flatten()

    # Geneformer format: [CLS] gene1 expr1 gene2 expr2 ... [SEP]
    tokens = [0]  # CLS token

    # Get non-zero genes sorted by expression
    non_zero_mask = expr_vector > 0
    non_zero_indices = np.where(non_zero_mask)[0]
    non_zero_expr = expr_vector[non_zero_indices]

    # Sort by expression (descending)
    sorted_indices = np.argsort(non_zero_expr)[::-1]
    top_genes = non_zero_indices[sorted_indices][:max_genes]

    # Add gene-expression pairs
    for gene_idx in top_genes:
        tokens.extend([gene_idx + 1, int(expr_vector[gene_idx])])

    tokens.append(1)  # SEP token
    token_sequences.append(tokens)
```

### SLAF Approach (Streaming)

```python
# Streaming tokenizer with familiar interface
slaf = SLAFArray("data.slaf")

# Create tokenizer
tokenizer = SLAFTokenizer(
    slaf_array=slaf,
    vocab_size=50000,
    n_expression_bins=10,
    chunk_size=1024,
)

# Tokenize cells for training
tokens = tokenizer.tokenize_geneformer(
    cell_integer_id_range=(0, 2048),
    max_genes=2048
)

# Stream to training loop
for batch in tokens:
    train_step(batch)
```

### Performance Results

| Configuration                 | Cells/sec | Tokens/sec | Batch Size | Max Genes | Total Speedup |
| ----------------------------- | --------- | ---------- | ---------- | --------- | ------------- |
| Geneformer small batch        | 1,933     | 1,979,732  | 32         | 1024      | **1.4x**      |
| Geneformer medium batch       | 5,140     | 10,527,183 | 128        | 2048      | **1.1x**      |
| Geneformer large batch        | 10,889    | 22,300,658 | 512        | 2048      | **1.2x**      |
| Geneformer xlarge batch       | 14,536    | 29,769,583 | 2048       | 2048      | **1.0x**      |
| Geneformer xlarge with filter | 19,054    | 39,022,639 | 2048       | 2048      | **1.8x**      |

**Key Insight**: SLAF's **streaming architecture** enables ML training on datasets that would crash traditional tools.

## üìà Performance Trends

As datasets grow larger, SLAF's advantages become more pronounced:

| Dataset Size | Traditional Memory | SLAF Memory | Efficiency Gain |
| ------------ | ------------------ | ----------- | --------------- |
| 1K cells     | 4 MB               | 0.8 MB      | 5x              |
| 10K cells    | 40 MB              | 8 MB        | 5x              |
| 50K cells    | 200 MB             | 40 MB       | 5x              |
| 100K cells   | 400 MB             | 80 MB       | 5x              |

**SLAF provides consistent memory efficiency across dataset sizes.**

## ‚ö†Ô∏è Caveats & Limitations

### Performance Trade-offs

- **Individual queries** may be slower than h5ad for simple operations
- **Small datasets** (<1K cells) may not benefit significantly
- **Complex aggregations** are still being optimized
- **Lazy processing** has real computational cost when materializing results

### Compatibility Considerations

- **AnnData API compatibility** is partial - some operations differ
- **Scanpy integration** requires adapter patterns for some workflows
- **Legacy code** may need refactoring to leverage lazy evaluation

### When Traditional Tools May Be Better

- **Simple workflows** with small datasets
- **Legacy pipelines** that heavily depend on AnnData APIs
- **Operations** where SLAF is still being optimized
- **Lazy processing workflows** that require frequent materialization

## üèÉ‚Äç‚ôÇÔ∏è Test SLAF's Performance

Run the benchmarks on your own data:

```bash
# Run comprehensive benchmarks
python benchmarks/run_comprehensive_benchmarks.py --datasets pbmc3k --auto-convert

# Run specific benchmark types
python benchmarks/run_comprehensive_benchmarks.py --types cell_filtering expression_queries

# Run on larger datasets (when available)
python benchmarks/run_comprehensive_benchmarks.py --datasets synthetic_50k --auto-convert
```

## üéØ Conclusion

SLAF represents a **paradigm shift** in single-cell analysis:

- **Capability expansion** - enables workflows impossible with traditional tools
- **Memory efficiency** - processes datasets that crash other tools
- **Lazy evaluation** - chains operations without memory explosions
- **ML-optimized** - streams data to training loops efficiently

### **Realistic Performance Summary**

Based on comprehensive benchmarks across 64 scenarios:

- **Average speedup**: 1.4x (modest improvements)
- **Memory efficiency**: 4.2x average (significant memory savings)
- **Best performing**: Cell filtering (2.4x speedup)
- **Needs attention**: Lazy processing (0.4x speedup due to materialization costs)

### **Key Insights**

1. **Memory efficiency is the primary advantage** - SLAF uses 4.2x less memory on average
2. **Speed improvements are modest** - 1.4x average speedup across all operations
3. **Lazy processing has real costs** - materializing lazy operations can be slower than eager execution
4. **Cell and gene filtering excel** - 2.3-2.4x speedup with 5.2-5.3x memory efficiency
5. **Expression queries are competitive** - 1.0x average speedup with 5.5x memory efficiency

Whether you're exploring small datasets or training ML models on millions of cells, SLAF provides the **capabilities and efficiency** you need for modern single-cell analysis, with a focus on memory efficiency and capability expansion rather than raw speed improvements.
