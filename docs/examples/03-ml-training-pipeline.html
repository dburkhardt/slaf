<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <link rel="icon" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.14.0/dist/favicon.ico" />
    <!-- Preload is necessary because we show these images when we disconnect from the server,
    but at that point we cannot load these images from the server -->
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.14.0/dist/assets/gradient-yHQUC_QB.png" as="image" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.14.0/dist/assets/noise-60BoTA8O.png" as="image" />
    <!-- Preload the fonts -->
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.14.0/dist/assets/Lora-VariableFont_wght-B2ootaw-.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.14.0/dist/assets/PTSans-Regular-CxL0S8W7.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.14.0/dist/assets/PTSans-Bold-D9fedIX3.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.14.0/dist/assets/FiraMono-Regular-BTCkDNvf.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.14.0/dist/assets/FiraMono-Medium-DU3aDxX5.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.14.0/dist/assets/FiraMono-Bold-CLVRCuM9.ttf" as="font" crossorigin="anonymous" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="theme-color" content="#000000" />
    <meta name="description" content="a marimo app" />
    <link rel="apple-touch-icon" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.14.0/dist/apple-touch-icon.png" />
    <link rel="manifest" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.14.0/dist/manifest.json" />

    <script data-marimo="true">
      function __resizeIframe(obj) {
        var scrollbarHeight = 20; // Max between windows, mac, and linux

        function setHeight() {
          var element = obj.contentWindow.document.documentElement;
          // If there is no vertical scrollbar, we don't need to resize the iframe
          if (element.scrollHeight === element.clientHeight) {
            return;
          }

          // Create a new height that includes the scrollbar height if it's visible
          var hasHorizontalScrollbar = element.scrollWidth > element.clientWidth;
          var newHeight = element.scrollHeight + (hasHorizontalScrollbar ? scrollbarHeight : 0);

          // Only update the height if it's different from the current height
          if (obj.style.height !== `${newHeight}px`) {
            obj.style.height = `${newHeight}px`;
          }
        }

        // Resize the iframe to the height of the content and bottom scrollbar height
        setHeight();

        // Resize the iframe when the content changes
        const resizeObserver = new ResizeObserver((entries) => {
          setHeight();
        });
        resizeObserver.observe(obj.contentWindow.document.body);
      }
    </script>
    <marimo-filename hidden>03-ml-training-pipeline.py</marimo-filename>
    <title>03-ml-training-pipeline</title>
    <script type="module" crossorigin crossorigin="anonymous" src="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.14.0/dist/assets/index-_Zd2Tjcq.js"></script>
    <link rel="stylesheet" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.14.0/dist/assets/index-BVt8Dtzn.css">

<script data-marimo="true">
    window.__MARIMO_STATIC__ = {};
    window.__MARIMO_STATIC__.files = {};
</script>
</head>
  <body>
    <div id="root"></div>
    <script data-marimo="true">
      window.__MARIMO_MOUNT_CONFIG__ = {
            "filename": "03-ml-training-pipeline.py",
            "mode": "read",
            "version": "0.14.0",
            "serverToken": "static",
            "config": {"completion": {"activate_on_typing": true, "copilot": false}, "display": {"cell_output": "above", "code_editor_font_size": 14, "dataframes": "rich", "default_table_page_size": 10, "default_width": "medium", "theme": "light"}, "formatting": {"line_length": 79}, "keymap": {"overrides": {}, "preset": "default"}, "language_servers": {"pylsp": {"enable_flake8": false, "enable_mypy": true, "enable_pydocstyle": false, "enable_pyflakes": false, "enable_pylint": false, "enable_ruff": true, "enabled": true}}, "package_management": {"manager": "pip"}, "runtime": {"auto_instantiate": true, "auto_reload": "off", "default_sql_output": "auto", "on_cell_change": "autorun", "output_max_bytes": 8000000, "reactive_tests": true, "std_stream_max_bytes": 1000000, "watcher_on_save": "lazy"}, "save": {"autosave": "after_delay", "autosave_delay": 1000, "format_on_save": false}, "server": {"browser": "default", "follow_symlink": false}, "snippets": {"custom_paths": [], "include_default_snippets": true}},
            "configOverrides": {},
            "appConfig": {"sql_output": "auto", "width": "medium"},
            "view": {"showAppCode": true},
            "notebook": {"cells": [{"code": "import time\n\nimport marimo as mo\nimport numpy as np\n\nfrom slaf import SLAFArray\nfrom slaf.ml.dataloaders import SLAFDataLoader\nfrom slaf.ml.tokenizers import SLAFTokenizer\n", "code_hash": "72bd3eb48288fa44e643be397d86a48d", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "Hbol", "name": "_"}, {"code": "mo.md(\n    \"\"\"\n# SLAF ML Training Pipeline\n\nThis notebook demonstrates how to build complete ML training pipelines with SLAF, including:\n\n- Streaming DataLoader with async prefetching\n- PyTorch-compatible datasets\n- Performance optimization techniques\n- Custom training loop examples\n\n**Key Benefits for ML Training:**\n\n\ud83d\udcbe **Memory Efficient**: Stream data in chunks without loading everything into memory\n\n\ud83d\udd04 **Flexible**: Support for different tokenization strategies (scGPT, Geneformer)\n\n\ud83e\uddec **High Throughput**: Load and tokenize cells at 10k cells / sec: fast enough to never let a 8 x H100 GPU node stay idle\n\"\"\"\n)", "code_hash": "0fb01cf133a2d5ccf4c34b375c92183a", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "MJUe", "name": "_"}, {"code": "# Load SLAF dataset for ML examples\nslaf = SLAFArray(\"../slaf-datasets/pbmc3k_processed.slaf\")\nprint(f\"\u2705 Loaded SLAF dataset: {slaf.shape[0]:,} cells \u00d7 {slaf.shape[1]:,} genes\")\n\n# Show dataset info\nslaf.info()", "code_hash": "11e373832fc301071b83d550f10621c3", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "vblA", "name": "_"}, {"code": "mo.md(\n    \"\"\"\n## 2. Tokenization Strategies\n\nSLAF supports different tokenization strategies for different model architectures.\nEach strategy has its own format and vocabulary structure:\n\"\"\"\n)", "code_hash": "7059d0c0f89a5cd3fdfe54bff6581e31", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "bkHC", "name": "_"}, {"code": "mo.md(\n    \"\"\"\n### GeneFormer vs scGPT Tokenization\n\n**GeneFormer**: Simple gene sequences sorted by expression\n- Format: `[CLS, gene1, gene2, gene3, ..., SEP]`\n- Vocabulary: Gene tokens only\n- Use case: Models that only need gene identity\n\n**scGPT**: Gene-expression pairs with special tokens\n- Format: `[CLS, gene1, expr1, gene2, expr2, ..., SEP]`\n- Vocabulary: Gene tokens + expression bin tokens\n- Use case: Models that need both gene identity and expression levels\n\"\"\"\n)", "code_hash": "659a75c2c2fe545b1f8d4085b057c1f1", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "lEQa", "name": "_"}, {"code": "def create_tokenizer():\n    # Create tokenizer with custom settings\n    tokenizer = SLAFTokenizer(\n        slaf_array=slaf,\n        vocab_size=2000,  # Dataset has <2000 genes\n        n_expression_bins=20,  # More expression bins\n    )\n\n    # Get vocabulary information\n    vocab_info = tokenizer.get_vocab_info()\n    print(\"\u2705 Tokenizer initialized:\")\n    print(f\"   Total vocabulary size: {vocab_info['vocab_size']:,}\")\n    print(f\"   Special tokens: {vocab_info['special_tokens']}\")\n    print(f\"   Expression bins: {vocab_info['n_expression_bins']}\")\n    print(f\"   Gene vocabulary size: {vocab_info['gene_vocab_size']:,}\")\n\n    # Show special tokens\n    print(\"\\nSpecial tokens:\")\n    for token_name, token_id in tokenizer.special_tokens.items():\n        print(f\"   {token_name}: {token_id}\")\n\n    return tokenizer\n\ntokenizer = create_tokenizer()", "code_hash": "c6819c2d7a1bc6b30be23573970d2427", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "PKri", "name": "_"}, {"code": "def demonstrate_geneformer():\n    print(\"\ud83e\uddec GeneFormer Tokenization & Decoding\")\n    print(\"=\" * 40)\n\n    # Create GeneFormer tokenizer\n    tokenizer = SLAFTokenizer(\n        slaf_array=slaf,\n        tokenizer_type=\"geneformer\",\n        vocab_size=2000,  # Dataset has <2000 genes\n        n_expression_bins=20,\n    )\n\n    # Show vocabulary info\n    vocab_info = tokenizer.get_vocab_info()\n    print(\n        f\"\u2705 Vocabulary: {vocab_info['vocab_size']} total tokens, {vocab_info['gene_vocab_size']} genes\"\n    )\n    print(f\"   Special tokens: {vocab_info['special_tokens']}\")\n\n    # Create sample gene sequences\n    gene_sequences = [[0, 1, 2, 3, 4], [1, 2, 3, 4, 5], [0, 2, 4, 6, 8]]\n\n    # Tokenize\n    input_ids, attention_mask = tokenizer.tokenize(\n        gene_sequences=gene_sequences,\n        max_genes=50,\n    )\n\n    print(\"\\n\ud83d\udcca Tokenization Results:\")\n    print(f\"   Input shape: {input_ids.shape}\")\n    print(f\"   Attention mask shape: {attention_mask.shape}\")\n    print(f\"   First sequence tokens: {input_ids[0].tolist()[:10]}...\")\n    print(f\"   First sequence attention: {attention_mask[0].tolist()[:10]}...\")\n\n    # Decode first sequence\n    print(\"\\n\ud83d\udd0d Decoding Results:\")\n    decoded = tokenizer.decode_tokens(input_ids[0].tolist())\n    print(f\"   Sequence length: {len(input_ids[0])}\")\n    print(f\"   Genes: {len(decoded['genes'])} genes\")\n    print(f\"   First few genes: {decoded['genes'][:5]}\")\n\n    return tokenizer, input_ids, attention_mask\n\ngeneformer_tokenizer, geneformer_input_ids, geneformer_attention_mask = (\n    demonstrate_geneformer()\n)", "code_hash": "6ca60f77424ce53a4f390250ff1ac1c8", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "Xref", "name": "_"}, {"code": "def demonstrate_scgpt():\n    print(\"\ud83e\uddec scGPT Tokenization & Decoding\")\n    print(\"=\" * 40)\n\n    # Create scGPT tokenizer\n    tokenizer = SLAFTokenizer(\n        slaf_array=slaf,\n        tokenizer_type=\"scgpt\",\n        vocab_size=2000,  # Dataset has <2000 genes\n        n_expression_bins=20,\n    )\n\n    # Show vocabulary info\n    vocab_info = tokenizer.get_vocab_info()\n    print(\n        f\"\u2705 Vocabulary: {vocab_info['vocab_size']} total tokens, {vocab_info['gene_vocab_size']} genes\"\n    )\n    print(f\"   Special tokens: {vocab_info['special_tokens']}\")\n    print(\n        f\"   Expression bins: {vocab_info['n_expression_bins']} bins (start at token {tokenizer.expr_bin_start})\"\n    )\n\n    # Create sample gene and expression sequences\n    gene_sequences = [[0, 1, 2], [1, 2, 3]]\n    expr_sequences = [[0.5, 0.8, 0.2], [0.9, 0.1, 0.7]]\n\n    # Tokenize\n    input_ids, attention_mask = tokenizer.tokenize(\n        gene_sequences=gene_sequences,\n        expr_sequences=expr_sequences,\n        max_genes=25,\n    )\n\n    print(\"\\n\ud83d\udcca Tokenization Results:\")\n    print(f\"   Input shape: {input_ids.shape}\")\n    print(f\"   Attention mask shape: {attention_mask.shape}\")\n    print(\"   Expected length: 1 + 2*25 + 1 = 52 (CLS + 25*(gene+expr) + SEP)\")\n    print(f\"   First sequence tokens: {input_ids[0].tolist()[:10]}...\")\n    print(f\"   First sequence attention: {attention_mask[0].tolist()[:10]}...\")\n\n    # Decode first sequence\n    print(\"\\n\ud83d\udd0d Decoding Results:\")\n    decoded = tokenizer.decode_tokens(input_ids[0].tolist())\n    print(f\"   Sequence length: {len(input_ids[0])}\")\n    print(f\"   Genes: {len(decoded['genes'])} genes\")\n    print(f\"   Expressions: {len(decoded['expressions'])} expressions\")\n    print(f\"   First few genes: {decoded['genes'][:3]}\")\n    print(f\"   First few expressions: {decoded['expressions'][:3]}\")\n\n    return tokenizer, input_ids, attention_mask\n\nscgpt_tokenizer, scgpt_input_ids, scgpt_attention_mask = demonstrate_scgpt()", "code_hash": "505c4aac3c6364cef4d212cc18cf5663", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "SFPL", "name": "_"}, {"code": "mo.md(\n    \"\"\"\n## 3. SLAF DataLoader - Production-Ready Training\n\nSLAF provides a high-performance DataLoader with streaming and async prefetching:\n\"\"\"\n)", "code_hash": "fac3821bbf2e279e65f8e4c45e3a90e9", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "BYtC", "name": "_"}, {"code": "mo.md(r\"\"\"### DataLoader Configuration\"\"\")", "code_hash": "e2ce151e7e27dc728be2a1c890e32375", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "RGSE", "name": "_"}, {"code": "def create_dataloader():\n    # Initialize DataLoader\n    print(\"\ud83d\udce6 SLAF DataLoader Configuration\")\n    print(\"=\" * 40)\n\n    # Create DataLoader with custom settings\n    dataloader = SLAFDataLoader(\n        slaf_array=slaf,\n        tokenizer_type=\"geneformer\",  # or \"scgpt\"\n        batch_size=16,  # Small batch for demo\n        max_genes=100,\n        vocab_size=2000,  # Dataset has <2000 genes\n        n_expression_bins=20,\n        n_epochs=1,  # Number of epochs\n    )\n\n    print(\"\u2705 DataLoader initialized:\")\n    print(f\"   Tokenizer type: {dataloader.tokenizer_type}\")\n    print(f\"   Batch size: {dataloader.batch_size}\")\n    print(f\"   Max genes: {dataloader.max_genes}\")\n    print(f\"   Special tokens: {dataloader.special_tokens}\")\n    print(f\"   Number of epochs: {dataloader.n_epochs}\")\n\n    return dataloader\n\ncreate_dataloader()", "code_hash": "5637fd76025461bcadeafa6844bbfb54", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "Kclp", "name": "_"}, {"code": "mo.md(r\"\"\"### DataLoader Iteration\"\"\")", "code_hash": "66cbeba1abd12994c4ffadf57168fd13", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "emfo", "name": "_"}, {"code": "def demonstrate_dataloader_iteration():\n    # Demonstrate DataLoader iteration\n    print(\"\ud83d\udd04 DataLoader Iteration\")\n    print(\"=\" * 25)\n\n    # Create dataloader\n    dataloader = SLAFDataLoader(\n        slaf_array=slaf,\n        tokenizer_type=\"geneformer\",  # or \"scgpt\"\n        batch_size=16,  # Small batch for demo\n        max_genes=100,\n        vocab_size=2000,  # Dataset has <2000 genes\n        n_expression_bins=20,\n        n_epochs=1,  # Number of epochs\n    )\n\n    # Get first batch\n    print(\"1. First batch structure:\")\n    batch = next(iter(dataloader))\n\n    for key, value in batch.items():\n        if hasattr(value, \"shape\"):\n            print(f\"   {key}: {type(value)} with shape {value.shape}\")\n        else:\n            print(f\"   {key}: {type(value)} with length {len(value)}\")\n\n    # Show batch details\n    input_ids = batch[\"input_ids\"]\n    attention_mask = batch[\"attention_mask\"]\n    cell_ids = batch[\"cell_ids\"]\n\n    print(\"\\n2. Batch details:\")\n    print(f\"   Input IDs shape: {input_ids.shape}\")\n    print(f\"   Attention mask shape: {attention_mask.shape}\")\n    print(f\"   Cell IDs shape: {cell_ids.shape}\")\n    print(f\"   Data type: {input_ids.dtype}\")\n\n    # Show sample tokens\n    print(\"\\n3. Sample tokens from first sequence:\")\n    first_seq = input_ids[0]\n    print(f\"   First 10 tokens: {first_seq[:10].tolist()}\")\n    print(f\"   Sequence length: {len(first_seq)}\")\n\ndemonstrate_dataloader_iteration()", "code_hash": "661e4382b80c809f90eefb4d2c1e07d1", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "Hstk", "name": "_"}, {"code": "mo.md(r\"\"\"### Performance Testing\"\"\")", "code_hash": "c21bf2bc264b66c6812c10c84fbbee08", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "nWHF", "name": "_"}, {"code": "def test_dataloader_performance():\n    # Performance testing of DataLoader\n    print(\"\u26a1 DataLoader Performance\")\n    print(\"=\" * 30)\n\n    # Create dataloader\n    dataloader = SLAFDataLoader(\n        slaf_array=slaf,\n        tokenizer_type=\"geneformer\",  # or \"scgpt\"\n        batch_size=16,  # Small batch for demo\n        max_genes=100,\n        vocab_size=2000,  # Dataset has <2000 genes\n        n_expression_bins=20,\n        n_epochs=1,  # Number of epochs\n    )\n\n    # Test iteration speed\n    print(\"1. Iteration performance:\")\n\n    batch_count = 0\n    total_tokens = 0\n\n    start_time = time.time()\n    for batch in dataloader:\n        batch_count += 1\n        total_tokens += batch[\"input_ids\"].shape[0] * batch[\"input_ids\"].shape[1]\n\n        # Only process first few batches for demo\n        if batch_count >= 5:\n            break\n\n    elapsed_time = time.time() - start_time\n\n    print(f\"   Processed {batch_count} batches in {elapsed_time:.4f}s\")\n    print(f\"   Total tokens: {total_tokens:,}\")\n    print(f\"   Tokens per second: {total_tokens / elapsed_time:,.0f}\")\n    print(f\"   Batches per second: {batch_count / elapsed_time:.2f}\")\n\ntest_dataloader_performance()", "code_hash": "b0110a415106e094723bdad0f9bc6d86", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "iLit", "name": "_"}, {"code": "mo.md(\n    \"\"\"\n## 5. PyTorch Training Loop Integration\n\nHere's how to integrate SLAF DataLoader with PyTorch training:\n\"\"\"\n)", "code_hash": "974e2b150b9e598622d517545e946b26", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "ZHCJ", "name": "_"}, {"code": "def demonstrate_pytorch_integration():\n    # Demonstrate PyTorch integration\n    print(\"\ud83d\udd25 PyTorch Training Loop Integration\")\n    print(\"=\" * 45)\n\n    # Reinitialize DataLoader since the previous one was exhausted\n    dataloader = SLAFDataLoader(\n        slaf_array=slaf,\n        tokenizer_type=\"geneformer\",\n        batch_size=16,\n        max_genes=100,\n        vocab_size=2000,  # Dataset has <2000 genes\n        n_expression_bins=20,\n        n_epochs=1,\n    )\n\n    # Check if PyTorch is available\n    try:\n        import torch\n\n        TORCH_AVAILABLE = True\n        print(\"\u2705 PyTorch is available\")\n    except ImportError:\n        TORCH_AVAILABLE = False\n        print(\"\u26a0\ufe0f PyTorch not available - showing numpy-based approach\")\n\n    if TORCH_AVAILABLE:\n        print(\"\\n1. PyTorch tensor conversion:\")\n        batch = next(iter(dataloader))\n\n        # Get device info\n        from slaf.ml.dataloaders import get_device_info, get_optimal_device\n\n        device_info = get_device_info()\n        optimal_device = get_optimal_device()\n\n        print(f\"   Device info: {device_info}\")\n        print(f\"   Using device: {optimal_device}\")\n\n        # Convert to PyTorch tensors on optimal device\n        input_ids_tensor = torch.tensor(\n            batch[\"input_ids\"], dtype=torch.long, device=optimal_device\n        )\n        attention_mask_tensor = torch.tensor(\n            batch[\"attention_mask\"], dtype=torch.bool, device=optimal_device\n        )\n        cell_ids_tensor = torch.tensor(\n            batch[\"cell_ids\"], dtype=torch.long, device=optimal_device\n        )\n\n        print(\n            f\"   Input IDs tensor: {input_ids_tensor.shape}, {input_ids_tensor.dtype}\"\n        )\n        print(\n            f\"   Attention mask tensor: {attention_mask_tensor.shape}, {attention_mask_tensor.dtype}\"\n        )\n        print(\n            f\"   Cell IDs tensor: {cell_ids_tensor.shape}, {cell_ids_tensor.dtype}\"\n        )\n\n        print(\"\\n2. Simple training loop structure:\")\n        print(\n            \"\"\"\n        # Training loop example with smart device detection\n        from slaf.ml.dataloaders import get_optimal_device\n\n        device = get_optimal_device()\n        model = YourModel(vocab_size=tokenizer.get_vocab_info()['vocab_size'])\n        model = model.to(device)  # Move model to optimal device\n        optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n\n        for epoch in range(num_epochs):\n            model.train()\n            for batch in dataloader:\n                # DataLoader already provides tensors on optimal device\n                input_ids = batch[\"input_ids\"]  # Already on device\n                attention_mask = batch[\"attention_mask\"]  # Already on device\n\n                # Forward pass\n                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n                loss = outputs.loss\n\n                # Backward pass\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n        \"\"\"\n        )\n\n    else:\n        print(\"\\n1. Numpy-based approach:\")\n        batch = next(iter(dataloader))\n        print(\n            f\"   Input IDs: {batch['input_ids'].shape}, {batch['input_ids'].dtype}\"\n        )\n        print(\n            f\"   Attention mask: {batch['attention_mask'].shape}, {batch['attention_mask'].dtype}\"\n        )\n        print(f\"   Cell IDs: {batch['cell_ids'].shape}, {batch['cell_ids'].dtype}\")\n\ndemonstrate_pytorch_integration()", "code_hash": "946736e7011b29e8ef3dc2e13908f15d", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "ROlb", "name": "_"}, {"code": "mo.md(\n    \"\"\"\n## 6. Streaming Dataset Features\n\nLearn about the new streaming dataset capabilities:\n\"\"\"\n)", "code_hash": "1b811e598f3c025a178c2a68f07ef92a", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "qnkX", "name": "_"}, {"code": "mo.md(r\"\"\"### Async Prefetching\"\"\")", "code_hash": "72d558332e89660b7c1ee6fd4de897a6", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "TqIu", "name": "_"}, {"code": "def demonstrate_streaming_features():\n    print(\"\ud83d\udd04 Streaming Dataset Features\")\n    print(\"=\" * 35)\n\n    # Create dataloader with streaming features\n    dataloader = SLAFDataLoader(\n        slaf_array=slaf,\n        tokenizer_type=\"geneformer\",\n        batch_size=8,\n        max_genes=50,\n        n_epochs=1,  # Single epoch for demo\n    )\n\n    print(\"\u2705 Streaming features:\")\n    print(\"   - Async fragment prefetching\")\n    print(\"   - Background fragment loading\")\n    print(\"   - Memory-efficient streaming\")\n    print(\"   - PyTorch IterableDataset compatibility\")\n\n    # Test streaming iteration\n    print(\"\\n\ud83d\udd04 Testing streaming iteration:\")\n    batch_count = 0\n    for batch in dataloader:\n        batch_count += 1\n        print(f\"   Batch {batch_count}: {batch['input_ids'].shape}\")\n        if batch_count >= 3:\n            break\n\n    print(f\"   Successfully streamed {batch_count} batches\")\n\ndemonstrate_streaming_features()", "code_hash": "9f8e3d4d9b824ca58100962fef3a58fa", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "Vxnm", "name": "_"}, {"code": "mo.md(r\"\"\"### Device Optimization\"\"\")", "code_hash": "3a7669a9d79b4c6daae0ea470c3f376d", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "DnEU", "name": "_"}, {"code": "def demonstrate_device_optimization():\n    print(\"\u26a1 Device Optimization\")\n    print(\"=\" * 25)\n\n    from slaf.ml.dataloaders import get_device_info, get_optimal_device\n\n    # Get device information\n    device_info = get_device_info()\n    optimal_device = get_optimal_device()\n\n    print(\"\u2705 Device detection:\")\n    print(f\"   PyTorch available: {device_info['torch_available']}\")\n    print(f\"   CUDA available: {device_info['cuda_available']}\")\n    print(f\"   MPS available: {device_info['mps_available']}\")\n    print(f\"   Optimal device: {optimal_device}\")\n\n    # Create dataloader with device optimization\n    dataloader = SLAFDataLoader(\n        slaf_array=slaf,\n        tokenizer_type=\"geneformer\",\n        batch_size=8,\n        max_genes=50,\n        n_epochs=1,\n    )\n\n    print(\"\\n\u2705 Device optimization:\")\n    print(\"   - Automatic device detection\")\n    print(\"   - Tensor transfer to optimal device\")\n    print(\"   - Memory-efficient device handling\")\n\n    # Test device transfer\n    batch = next(iter(dataloader))\n    if hasattr(batch[\"input_ids\"], \"device\"):\n        print(f\"   Batch device: {batch['input_ids'].device}\")\n\ndemonstrate_device_optimization()", "code_hash": "f40d49586401d4a147ababb814e3708a", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "ulZA", "name": "_"}, {"code": "mo.md(\n    \"\"\"\n## 7. Advanced Tokenization Features\n\nExplore advanced tokenization features and optimizations:\n\"\"\"\n)", "code_hash": "386d06b7004b213dcdae8da48515cc39", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "ecfG", "name": "_"}, {"code": "def demonstrate_advanced_features():\n    # Advanced tokenization features\n    print(\"\ud83d\ude80 Advanced Tokenization Features\")\n    print(\"=\" * 40)\n\n    print(\"1. Different max_genes settings:\")\n    gene_sequences = [[i, i + 1, i + 2] for i in range(20)]\n\n    for max_genes in [25, 50, 100]:\n        input_ids, attention_mask = tokenizer.tokenize(\n            gene_sequences=gene_sequences,\n            max_genes=max_genes,\n        )\n        avg_length = np.mean([len(seq) for seq in input_ids])\n        print(f\"   max_genes={max_genes}: avg_length={avg_length:.1f}\")\n\n    print(\"\\n2. Different vocabulary sizes:\")\n    for vocab_size in [1000, 5000, 10000]:\n        # Create a new tokenizer with different vocab size\n        test_tokenizer = SLAFTokenizer(\n            slaf_array=tokenizer.slaf_array,\n            vocab_size=vocab_size,\n            n_expression_bins=10,\n        )\n        vocab_info = test_tokenizer.get_vocab_info()\n        print(\n            f\"   vocab_size={vocab_size}: actual_vocab={vocab_info['vocab_size']}\"\n        )\n\n    print(\"\\n3. Expression binning for scGPT:\")\n    # Test scGPT with different expression bins\n    gene_sequences = [[1, 2, 3], [2, 3, 4]]\n    expr_sequences = [[0.5, 0.8, 0.2], [0.9, 0.1, 0.7]]\n\n    for n_bins in [5, 10, 20]:\n        scgpt_tokenizer = SLAFTokenizer(\n            slaf_array=tokenizer.slaf_array,\n            tokenizer_type=\"scgpt\",\n            vocab_size=2000,  # Dataset has <2000 genes\n            n_expression_bins=n_bins,\n        )\n\n        start_time = time.time()\n        input_ids, attention_mask = scgpt_tokenizer.tokenize(\n            gene_sequences=gene_sequences,\n            expr_sequences=expr_sequences,\n            max_genes=25,\n        )\n        elapsed_time = time.time() - start_time\n\n        print(f\"   n_expression_bins={n_bins}: {elapsed_time:.4f}s\")\n\ndemonstrate_advanced_features()", "code_hash": "3318a2a147283f0fc5ab99f1676bd7cf", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "Pvdt", "name": "_"}, {"code": "mo.md(\n    \"\"\"\n## 8. Memory and Performance Optimization\n\nLearn how to optimize memory usage and performance for large-scale training:\n\"\"\"\n)", "code_hash": "1b959440c168991765eb13f6be153e02", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "ZBYS", "name": "_"}, {"code": "def demonstrate_memory_optimization():\n    # Memory and performance optimization\n    print(\"\ud83d\udcbe Memory and Performance Optimization\")\n    print(\"=\" * 45)\n\n    import gc\n\n    import psutil\n\n    def get_memory_usage():\n        \"\"\"Get current memory usage in MB\"\"\"\n        process = psutil.Process()\n        return process.memory_info().rss / 1024 / 1024\n\n    print(\"1. Memory usage comparison:\")\n\n    # Baseline memory\n    gc.collect()\n    baseline_memory = get_memory_usage()\n    print(f\"   Baseline memory: {baseline_memory:.1f} MB\")\n\n    # Memory with different batch sizes\n    for batch_size in [8, 16, 32]:\n        gc.collect()\n        start_memory = get_memory_usage()\n\n        dataloader = SLAFDataLoader(\n            slaf_array=slaf,\n            batch_size=batch_size,\n            max_genes=100,\n            vocab_size=2000,  # Dataset has <2000 genes\n            n_epochs=1,\n        )\n\n        # Process one batch\n        _ = next(iter(dataloader))\n        end_memory = get_memory_usage()\n\n        print(\n            f\"   Batch size {batch_size}: {end_memory:.1f} MB (+{end_memory - start_memory:.1f} MB)\"\n        )\n\n    print(\"\\n2. Performance with different settings:\")\n\n    # Test different configurations\n    configs = [\n        {\"batch_size\": 8, \"max_genes\": 50, \"description\": \"Small batches\"},\n        {\"batch_size\": 16, \"max_genes\": 100, \"description\": \"Medium batches\"},\n        {\"batch_size\": 32, \"max_genes\": 200, \"description\": \"Large batches\"},\n    ]\n\n    for config in configs:\n        dataloader = SLAFDataLoader(\n            slaf_array=slaf,\n            **{k: v for k, v in config.items() if k != \"description\"},\n            n_epochs=1,\n        )\n\n        start_time = time.time()\n        batch_count = 0\n        for _ in dataloader:\n            batch_count += 1\n            if batch_count >= 3:  # Test first 3 batches\n                break\n\n        elapsed_time = time.time() - start_time\n        print(\n            f\"   {config['description']}: {elapsed_time:.4f}s for {batch_count} batches\"\n        )\n\ndemonstrate_memory_optimization()", "code_hash": "88c834fdd7a432db6284b773242c8564", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "aLJB", "name": "_"}, {"code": "mo.md(\n    \"\"\"\n## 9. Production Training Workflow\n\nComplete example of a production-ready training workflow:\n\"\"\"\n)", "code_hash": "8258f9bc568b2c9517ec0f036e28adba", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "nHfw", "name": "_"}, {"code": "def create_production_workflow():\n    # Production training workflow\n    print(\"\ud83c\udfed Production Training Workflow\")\n    print(\"=\" * 40)\n\n    # Create tokenizer\n    tokenizer = SLAFTokenizer(\n        slaf_array=slaf,\n        vocab_size=2000,  # Dataset has <2000 genes\n        n_expression_bins=50,\n    )\n\n    print(\n        f\"\u2705 Created tokenizer with {tokenizer.get_vocab_info()['vocab_size']} total tokens\"\n    )\n\n    # Create dataloaders (in production, you'd use proper splits)\n    train_dataloader = SLAFDataLoader(\n        slaf_array=slaf,\n        tokenizer_type=\"geneformer\",\n        batch_size=32,\n        max_genes=512,\n        vocab_size=2000,  # Dataset has <2000 genes\n        n_expression_bins=50,\n        n_epochs=1,\n    )\n\n    val_dataloader = SLAFDataLoader(\n        slaf_array=slaf,\n        tokenizer_type=\"geneformer\",\n        batch_size=32,\n        max_genes=512,\n        vocab_size=2000,  # Dataset has <2000 genes\n        n_expression_bins=50,\n        n_epochs=1,\n    )\n\n    print(\"\\n\ud83d\udcca Production Setup:\")\n    print(f\"   Batch size: {train_dataloader.batch_size}\")\n    print(f\"   Max genes: {train_dataloader.max_genes}\")\n\n    # Test production workflow\n    print(\"\\n\ud83e\uddea Testing production workflow:\")\n\n    # Test training batch\n    train_batch = next(iter(train_dataloader))\n    print(f\"   Training batch shape: {train_batch['input_ids'].shape}\")\n\n    # Test validation batch\n    val_batch = next(iter(val_dataloader))\n    print(f\"   Validation batch shape: {val_batch['input_ids'].shape}\")\n\n    return train_dataloader, val_dataloader, tokenizer\n\ncreate_production_workflow()", "code_hash": "e8f9dd52afbf0caccf09c320401d5d13", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "xXTn", "name": "_"}, {"code": "mo.md(\n    \"\"\"\n## 10. Best Practices for ML Training\n\nKey best practices for using SLAF in ML training:\n\"\"\"\n)", "code_hash": "98cb4ee253ef5535efaafb4033272c74", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "AjVT", "name": "_"}, {"code": "def show_best_practices():\n    # Best practices for ML training\n    print(\"\ud83d\udca1 Best Practices for ML Training\")\n    print(\"=\" * 40)\n\n    print(\"1. Tokenizer Configuration:\")\n    print(\"   \u2705 Choose appropriate vocab_size based on your dataset\")\n    print(\"   \u2705 Use n_expression_bins=50 for fine-grained expression modeling\")\n    print(\"   \u2705 Use the correct tokenizer_type for your model architecture\")\n\n    print(\"\\n2. DataLoader Configuration:\")\n    print(\"   \u2705 Start with small batch_size and increase gradually\")\n    print(\"   \u2705 Use max_genes appropriate for your model architecture\")\n    print(\"   \u2705 Set n_epochs for multi-epoch training on small datasets\")\n\n    print(\"\\n3. Performance Optimization:\")\n    print(\"   \u2705 Fragment-based processing is much faster than SQL\")\n    print(\"   \u2705 Use async prefetching to minimize GPU idle time\")\n    print(\"   \u2705 Leverage device optimization for automatic tensor transfer\")\n    print(\"   \u2705 Monitor memory usage during training\")\n\n    print(\"\\n4. Training Workflow:\")\n    print(\"   \u2705 Create separate train/val/test splits\")\n    print(\"   \u2705 Use consistent tokenizer across splits\")\n    print(\"   \u2705 Implement proper error handling\")\n    print(\"   \u2705 Use streaming datasets for large datasets\")\n\n    print(\"\\n5. Production Considerations:\")\n    print(\"   \u2705 Use appropriate batch sizes for your hardware\")\n    print(\"   \u2705 Implement checkpointing for long training runs\")\n    print(\"   \u2705 Monitor tokenization throughput\")\n    print(\"   \u2705 Consider distributed training for large datasets\")\n\nshow_best_practices()", "code_hash": "b1e3273965c01f86c1b65fb715e2c6da", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "pHFh", "name": "_"}, {"code": "mo.md(\n    \"\"\"\n## Summary\n\n**What you've learned about SLAF ML Training:**\n\n1. **Streaming DataLoader**: Async prefetching with PyTorch compatibility\n2. **Tokenization Strategies**: Geneformer and scGPT formats with optimized processing\n3. **Memory Efficiency**: Streaming datasets for large-scale training\n4. **Production Workflow**: Complete training pipeline setup\n5. **Best Practices**: Guidelines for optimal ML training performance\n\n**Key Performance Improvements:**\n- Fragment processing for high throughput\n- Streaming datasets with async prefetching\n- Automatic device optimization\n- Memory-efficient processing for large datasets\n\"\"\"\n)", "code_hash": "9df763a6c9d9d091cba8e90096846ad4", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "NCOB", "name": "_"}, {"code": "", "code_hash": null, "config": {"column": null, "disabled": false, "hide_code": false}, "id": "aqbW", "name": "_"}], "metadata": {"marimo_version": "0.14.0"}, "version": "1"},
            "session": {"cells": [{"code_hash": "72bd3eb48288fa44e643be397d86a48d", "console": [], "id": "Hbol", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "0fb01cf133a2d5ccf4c34b375c92183a", "console": [], "id": "MJUe", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><h1 id=\"slaf-ml-training-pipeline\">SLAF ML Training Pipeline</h1>\n<span class=\"paragraph\">This notebook demonstrates how to build complete ML training pipelines with SLAF, including:</span>\n<ul>\n<li>Streaming DataLoader with async prefetching</li>\n<li>PyTorch-compatible datasets</li>\n<li>Performance optimization techniques</li>\n<li>Custom training loop examples</li>\n</ul>\n<span class=\"paragraph\"><strong>Key Benefits for ML Training:</strong></span>\n<span class=\"paragraph\">\ud83d\udcbe <strong>Memory Efficient</strong>: Stream data in chunks without loading everything into memory</span>\n<span class=\"paragraph\">\ud83d\udd04 <strong>Flexible</strong>: Support for different tokenization strategies (scGPT, Geneformer)</span>\n<span class=\"paragraph\">\ud83e\uddec <strong>High Throughput</strong>: Load and tokenize cells at 10k cells / sec: fast enough to never let a 8 x H100 GPU node stay idle</span></span>"}, "type": "data"}]}, {"code_hash": "11e373832fc301071b83d550f10621c3", "console": [{"name": "stdout", "text": "\u2705 Loaded SLAF dataset: 2,695 cells \u00d7 1,863 genes\nSLAF Dataset\n  Shape: 2695 cells \u00d7 1863 genes\n  Format version: 0.1\n  Cell metadata columns: 9\n    n_genes, n_genes_by_counts, total_counts, leiden, batch...\n  Gene metadata columns: 12\n    gene_ids, n_cells, mt, n_cells_by_counts, mean_counts...\n  Record counts:\n    Cells: 2,695\n    Genes: 1,863\n    Expression records: computing...\n", "type": "stream"}, {"name": "stdout", "text": "    Expression records: 415,134\n  Optimizations:\n    use_integer_keys: True\n", "type": "stream"}], "id": "vblA", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "7059d0c0f89a5cd3fdfe54bff6581e31", "console": [], "id": "bkHC", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><h2 id=\"2-tokenization-strategies\">2. Tokenization Strategies</h2>\n<span class=\"paragraph\">SLAF supports different tokenization strategies for different model architectures.\nEach strategy has its own format and vocabulary structure:</span></span>"}, "type": "data"}]}, {"code_hash": "659a75c2c2fe545b1f8d4085b057c1f1", "console": [], "id": "lEQa", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><h3 id=\"geneformer-vs-scgpt-tokenization\">GeneFormer vs scGPT Tokenization</h3>\n<span class=\"paragraph\"><strong>GeneFormer</strong>: Simple gene sequences sorted by expression\n- Format: <code>[CLS, gene1, gene2, gene3, ..., SEP]</code>\n- Vocabulary: Gene tokens only\n- Use case: Models that only need gene identity</span>\n<span class=\"paragraph\"><strong>scGPT</strong>: Gene-expression pairs with special tokens\n- Format: <code>[CLS, gene1, expr1, gene2, expr2, ..., SEP]</code>\n- Vocabulary: Gene tokens + expression bin tokens\n- Use case: Models that need both gene identity and expression levels</span></span>"}, "type": "data"}]}, {"code_hash": "c6819c2d7a1bc6b30be23573970d2427", "console": [{"name": "stdout", "text": "\u2705 Tokenizer initialized:\n   Total vocabulary size: 2,000\n   Special tokens: {'PAD': 0, 'CLS': 1, 'SEP': 2, 'MASK': 3}\n   Expression bins: 20\n   Gene vocabulary size: 1,000\n\nSpecial tokens:\n   PAD: 0\n   CLS: 1\n   SEP: 2\n   MASK: 3\n", "type": "stream"}], "id": "PKri", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "6ca60f77424ce53a4f390250ff1ac1c8", "console": [{"name": "stdout", "text": "\ud83e\uddec GeneFormer Tokenization & Decoding\n========================================\n\u2705 Vocabulary: 2000 total tokens, 1000 genes\n   Special tokens: {'PAD': 0, 'CLS': 1, 'SEP': 2, 'MASK': 3}\n\n\ud83d\udcca Tokenization Results:\n   Input shape: torch.Size([3, 50])\n   Attention mask shape: torch.Size([3, 50])\n   First sequence tokens: [1, 4, 5, 6, 7, 8, 2, 0, 0, 0]...\n   First sequence attention: [True, True, True, True, True, True, True, False, False, False]...\n\n\ud83d\udd0d Decoding Results:\n   Sequence length: 50\n   Genes: 5 genes\n   First few genes: ['gene_0', 'gene_1', 'gene_2', 'gene_3', 'gene_4']\n", "type": "stream"}], "id": "Xref", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "505c4aac3c6364cef4d212cc18cf5663", "console": [{"name": "stdout", "text": "\ud83e\uddec scGPT Tokenization & Decoding\n========================================\n\u2705 Vocabulary: 2000 total tokens, 1000 genes\n   Special tokens: {'PAD': 0, 'CLS': 1, 'SEP': 2, 'MASK': 3}\n   Expression bins: 20 bins (start at token 2000)\n\n\ud83d\udcca Tokenization Results:\n   Input shape: torch.Size([2, 52])\n   Attention mask shape: torch.Size([2, 52])\n   Expected length: 1 + 2*25 + 1 = 52 (CLS + 25*(gene+expr) + SEP)\n   First sequence tokens: [1, 4, 2010, 5, 2016, 6, 2004, 2, 0, 0]...\n   First sequence attention: [True, True, True, True, True, True, True, True, False, False]...\n\n\ud83d\udd0d Decoding Results:\n   Sequence length: 52\n   Genes: 3 genes\n   Expressions: 3 expressions\n   First few genes: ['gene_0', 'gene_1', 'gene_2']\n   First few expressions: [0.5, 0.8, 0.2]\n", "type": "stream"}], "id": "SFPL", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "fac3821bbf2e279e65f8e4c45e3a90e9", "console": [], "id": "BYtC", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><h2 id=\"3-slaf-dataloader-production-ready-training\">3. SLAF DataLoader - Production-Ready Training</h2>\n<span class=\"paragraph\">SLAF provides a high-performance DataLoader with streaming and async prefetching:</span></span>"}, "type": "data"}]}, {"code_hash": "e2ce151e7e27dc728be2a1c890e32375", "console": [], "id": "RGSE", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><h3 id=\"dataloader-configuration\">DataLoader Configuration</h3></span>"}, "type": "data"}]}, {"code_hash": "5637fd76025461bcadeafa6844bbfb54", "console": [{"name": "stdout", "text": "\ud83d\udce6 SLAF DataLoader Configuration\n========================================\n", "type": "stream"}, {"name": "stdout", "text": "\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 Prefetch batch 0 (epoch 0):                                                                                                                                                                \u2502\n\u2502    Lance loading: 21.1ms (51 batches, 415134 rows)                                                                                                                                         \u2502\n\u2502    Processing: 12.6ms window, 15.4ms shuffle, 41.2ms tokenize                                                                                                                              \u2502\n\u2502    Total: 100.0ms, 2694 cells, 544.9 MB                                                                                                                                                    \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 \u2705 All 1 epochs completed                                                                                                                                                                  \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 \u2705 Prefetcher ready after 0.11s                                                                                                                                                            \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u2705 DataLoader initialized:\n   Tokenizer type: geneformer\n   Batch size: 16\n   Max genes: 100\n   Special tokens: {'PAD': 0, 'CLS': 1, 'SEP': 2, 'MASK': 3}\n   Number of epochs: 1\n", "type": "stream"}], "id": "Kclp", "outputs": [{"data": {"text/html": "<pre style='font-size: 12px'>&lt;slaf.ml.dataloaders.SLAFDataLoader object at 0x2a5d79d60&gt;</pre>"}, "type": "data"}]}, {"code_hash": "66cbeba1abd12994c4ffadf57168fd13", "console": [], "id": "emfo", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><h3 id=\"dataloader-iteration\">DataLoader Iteration</h3></span>"}, "type": "data"}]}, {"code_hash": "661e4382b80c809f90eefb4d2c1e07d1", "console": [{"name": "stdout", "text": "\ud83d\udd04 DataLoader Iteration\n=========================\n", "type": "stream"}, {"name": "stdout", "text": "\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 Prefetch batch 0 (epoch 0):                                                                                                                                                                \u2502\n\u2502    Lance loading: 17.8ms (51 batches, 415134 rows)                                                                                                                                         \u2502\n\u2502    Processing: 9.6ms window, 11.5ms shuffle, 26.9ms tokenize                                                                                                                               \u2502\n\u2502    Total: 69.3ms, 2694 cells, 656.5 MB                                                                                                                                                     \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 \u2705 All 1 epochs completed                                                                                                                                                                  \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n", "type": "stream"}, {"name": "stdout", "text": "\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 \u2705 Prefetcher ready after 0.11s                                                                                                                                                            \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n1. First batch structure:\n\ud83d\udd04 Epoch transition detected: -1 -> 0\n   input_ids: <class 'torch.Tensor'> with shape torch.Size([16, 2048])\n   attention_mask: <class 'torch.Tensor'> with shape torch.Size([16, 2048])\n   cell_ids: <class 'torch.Tensor'> with shape torch.Size([16])\n\n2. Batch details:\n   Input IDs shape: torch.Size([16, 2048])\n   Attention mask shape: torch.Size([16, 2048])\n   Cell IDs shape: torch.Size([16])\n   Data type: torch.int64\n\n3. Sample tokens from first sequence:\n   First 10 tokens: [1, 12, 20, 36, 55, 64, 71, 94, 113, 134]\n   Sequence length: 2048\n", "type": "stream"}], "id": "Hstk", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "c21bf2bc264b66c6812c10c84fbbee08", "console": [], "id": "nWHF", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><h3 id=\"performance-testing\">Performance Testing</h3></span>"}, "type": "data"}]}, {"code_hash": "b0110a415106e094723bdad0f9bc6d86", "console": [{"name": "stdout", "text": "\u26a1 DataLoader Performance\n==============================\n", "type": "stream"}, {"name": "stdout", "text": "\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 Prefetch batch 0 (epoch 0):                                                                                                                                                                \u2502\n\u2502    Lance loading: 16.8ms (51 batches, 415134 rows)                                                                                                                                         \u2502\n\u2502    Processing: 8.9ms window, 11.6ms shuffle, 24.8ms tokenize                                                                                                                               \u2502\n\u2502    Total: 65.8ms, 2694 cells, 687.6 MB                                                                                                                                                     \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 \u2705 All 1 epochs completed                                                                                                                                                                  \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n", "type": "stream"}, {"name": "stdout", "text": "\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 \u2705 Prefetcher ready after 0.11s                                                                                                                                                            \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n1. Iteration performance:\n\ud83d\udd04 Epoch transition detected: -1 -> 0\n   Processed 5 batches in 0.0004s\n   Total tokens: 163,840\n   Tokens per second: 441,641,881\n   Batches per second: 13477.84\n", "type": "stream"}], "id": "iLit", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "974e2b150b9e598622d517545e946b26", "console": [], "id": "ZHCJ", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><h2 id=\"5-pytorch-training-loop-integration\">5. PyTorch Training Loop Integration</h2>\n<span class=\"paragraph\">Here's how to integrate SLAF DataLoader with PyTorch training:</span></span>"}, "type": "data"}]}, {"code_hash": "946736e7011b29e8ef3dc2e13908f15d", "console": [{"name": "stdout", "text": "\ud83d\udd25 PyTorch Training Loop Integration\n=============================================\n", "type": "stream"}, {"name": "stdout", "text": "\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 Prefetch batch 0 (epoch 0):                                                                                                                                                                \u2502\n\u2502    Lance loading: 259.5ms (51 batches, 415134 rows)                                                                                                                                        \u2502\n\u2502    Processing: 84.9ms window, 24.0ms shuffle, 74.0ms tokenize                                                                                                                              \u2502\n\u2502    Total: 703.0ms, 2694 cells, 706.1 MB                                                                                                                                                    \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 \u2705 All 1 epochs completed                                                                                                                                                                  \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 \u2705 Prefetcher ready after 0.72s                                                                                                                                                            \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u2705 PyTorch is available\n\n1. PyTorch tensor conversion:\n\ud83d\udd04 Epoch transition detected: -1 -> 0\n   Device info: {'torch_available': True, 'cuda_available': False, 'mps_available': True, 'optimal_device': 'mps'}\n   Using device: mps\n", "type": "stream"}, {"name": "stderr", "text": "/var/folders/4g/t2xnyv255vd8pmccptg62wq80000gn/T/marimo_38842/__marimo__cell_ROlb_.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  input_ids_tensor = torch.tensor(\n", "type": "stream"}, {"name": "stderr", "text": "/var/folders/4g/t2xnyv255vd8pmccptg62wq80000gn/T/marimo_38842/__marimo__cell_ROlb_.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  attention_mask_tensor = torch.tensor(\n/var/folders/4g/t2xnyv255vd8pmccptg62wq80000gn/T/marimo_38842/__marimo__cell_ROlb_.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  cell_ids_tensor = torch.tensor(\n", "type": "stream"}, {"name": "stdout", "text": "   Input IDs tensor: torch.Size([16, 2048]), torch.int64\n   Attention mask tensor: torch.Size([16, 2048]), torch.bool\n   Cell IDs tensor: torch.Size([16]), torch.int64\n\n2. Simple training loop structure:\n\n        # Training loop example with smart device detection\n        from slaf.ml.dataloaders import get_optimal_device\n\n        device = get_optimal_device()\n        model = YourModel(vocab_size=tokenizer.get_vocab_info()['vocab_size'])\n        model = model.to(device)  # Move model to optimal device\n        optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n\n        for epoch in range(num_epochs):\n            model.train()\n            for batch in dataloader:\n                # DataLoader already provides tensors on optimal device\n                input_ids = batch[\"input_ids\"]  # Already on device\n                attention_mask = batch[\"attention_mask\"]  # Already on device\n\n                # Forward pass\n                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n                loss = outputs.loss\n\n                # Backward pass\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n        \n", "type": "stream"}], "id": "ROlb", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "1b811e598f3c025a178c2a68f07ef92a", "console": [], "id": "qnkX", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><h2 id=\"6-streaming-dataset-features\">6. Streaming Dataset Features</h2>\n<span class=\"paragraph\">Learn about the new streaming dataset capabilities:</span></span>"}, "type": "data"}]}, {"code_hash": "72d558332e89660b7c1ee6fd4de897a6", "console": [], "id": "TqIu", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><h3 id=\"async-prefetching\">Async Prefetching</h3></span>"}, "type": "data"}]}, {"code_hash": "9f8e3d4d9b824ca58100962fef3a58fa", "console": [{"name": "stdout", "text": "\ud83d\udd04 Streaming Dataset Features\n===================================\n", "type": "stream"}, {"name": "stdout", "text": "\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 Prefetch batch 0 (epoch 0):                                                                                                                                                                \u2502\n\u2502    Lance loading: 29.5ms (51 batches, 415134 rows)                                                                                                                                         \u2502\n\u2502    Processing: 10.0ms window, 12.3ms shuffle, 27.5ms tokenize                                                                                                                              \u2502\n\u2502    Total: 83.2ms, 2694 cells, 531.1 MB                                                                                                                                                     \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 \u2705 All 1 epochs completed                                                                                                                                                                  \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n", "type": "stream"}, {"name": "stdout", "text": "\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 \u2705 Prefetcher ready after 0.10s                                                                                                                                                            \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u2705 Streaming features:\n   - Async fragment prefetching\n   - Background fragment loading\n   - Memory-efficient streaming\n   - PyTorch IterableDataset compatibility\n\n\ud83d\udd04 Testing streaming iteration:\n\ud83d\udd04 Epoch transition detected: -1 -> 0\n   Batch 1: torch.Size([8, 2048])\n   Batch 2: torch.Size([8, 2048])\n   Batch 3: torch.Size([8, 2048])\n   Successfully streamed 3 batches\n", "type": "stream"}], "id": "Vxnm", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "3a7669a9d79b4c6daae0ea470c3f376d", "console": [], "id": "DnEU", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><h3 id=\"device-optimization\">Device Optimization</h3></span>"}, "type": "data"}]}, {"code_hash": "f40d49586401d4a147ababb814e3708a", "console": [{"name": "stdout", "text": "\u26a1 Device Optimization\n=========================\n\u2705 Device detection:\n   PyTorch available: True\n   CUDA available: False\n   MPS available: True\n   Optimal device: mps\n", "type": "stream"}, {"name": "stdout", "text": "\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 Prefetch batch 0 (epoch 0):                                                                                                                                                                \u2502\n\u2502    Lance loading: 18.1ms (51 batches, 415134 rows)                                                                                                                                         \u2502\n\u2502    Processing: 8.5ms window, 11.3ms shuffle, 26.0ms tokenize                                                                                                                               \u2502\n\u2502    Total: 67.2ms, 2694 cells, 571.0 MB                                                                                                                                                     \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 \u2705 All 1 epochs completed                                                                                                                                                                  \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n", "type": "stream"}, {"name": "stdout", "text": "\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 \u2705 Prefetcher ready after 0.10s                                                                                                                                                            \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\n\u2705 Device optimization:\n   - Automatic device detection\n   - Tensor transfer to optimal device\n   - Memory-efficient device handling\n\ud83d\udd04 Epoch transition detected: -1 -> 0\n   Batch device: cpu\n", "type": "stream"}], "id": "ulZA", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "386d06b7004b213dcdae8da48515cc39", "console": [], "id": "ecfG", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><h2 id=\"7-advanced-tokenization-features\">7. Advanced Tokenization Features</h2>\n<span class=\"paragraph\">Explore advanced tokenization features and optimizations:</span></span>"}, "type": "data"}]}, {"code_hash": "3318a2a147283f0fc5ab99f1676bd7cf", "console": [{"name": "stdout", "text": "\ud83d\ude80 Advanced Tokenization Features\n========================================\n1. Different max_genes settings:\n   max_genes=25: avg_length=25.0\n   max_genes=50: avg_length=50.0\n   max_genes=100: avg_length=100.0\n\n2. Different vocabulary sizes:\n   vocab_size=1000: actual_vocab=1000\n   vocab_size=5000: actual_vocab=5000\n   vocab_size=10000: actual_vocab=10000\n\n3. Expression binning for scGPT:\n   n_expression_bins=5: 0.0001s\n", "type": "stream"}, {"name": "stdout", "text": "   n_expression_bins=10: 0.0001s\n   n_expression_bins=20: 0.0001s\n", "type": "stream"}], "id": "Pvdt", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "1b959440c168991765eb13f6be153e02", "console": [], "id": "ZBYS", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><h2 id=\"8-memory-and-performance-optimization\">8. Memory and Performance Optimization</h2>\n<span class=\"paragraph\">Learn how to optimize memory usage and performance for large-scale training:</span></span>"}, "type": "data"}]}, {"code_hash": "88c834fdd7a432db6284b773242c8564", "console": [{"name": "stdout", "text": "\ud83d\udcbe Memory and Performance Optimization\n=============================================\n1. Memory usage comparison:\n", "type": "stream"}, {"name": "stdout", "text": "   Baseline memory: 652.5 MB\n", "type": "stream"}, {"name": "stdout", "text": "\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 Prefetch batch 0 (epoch 0):                                                                                                                                                                \u2502\n\u2502    Lance loading: 16.0ms (51 batches, 415134 rows)                                                                                                                                         \u2502\n\u2502    Processing: 9.3ms window, 10.3ms shuffle, 26.1ms tokenize                                                                                                                               \u2502\n\u2502    Total: 64.8ms, 2694 cells, 663.6 MB                                                                                                                                                     \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 \u2705 All 1 epochs completed                                                                                                                                                                  \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n", "type": "stream"}, {"name": "stdout", "text": "\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 \u2705 Prefetcher ready after 0.11s                                                                                                                                                            \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\ud83d\udd04 Epoch transition detected: -1 -> 0\n   Batch size 8: 684.5 MB (+32.0 MB)\n", "type": "stream"}, {"name": "stdout", "text": "\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 Prefetch batch 0 (epoch 0):                                                                                                                                                                \u2502\n\u2502    Lance loading: 17.0ms (51 batches, 415134 rows)                                                                                                                                         \u2502\n\u2502    Processing: 9.1ms window, 10.7ms shuffle, 39.8ms tokenize                                                                                                                               \u2502\n\u2502    Total: 79.9ms, 2694 cells, 700.9 MB                                                                                                                                                     \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 \u2705 All 1 epochs completed                                                                                                                                                                  \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n", "type": "stream"}, {"name": "stdout", "text": "\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 \u2705 Prefetcher ready after 0.11s                                                                                                                                                            \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\ud83d\udd04 Epoch transition detected: -1 -> 0\n   Batch size 16: 763.2 MB (+78.7 MB)\n", "type": "stream"}, {"name": "stdout", "text": "\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 Prefetch batch 0 (epoch 0):                                                                                                                                                                \u2502\n\u2502    Lance loading: 16.3ms (51 batches, 415134 rows)                                                                                                                                         \u2502\n\u2502    Processing: 8.4ms window, 10.7ms shuffle, 25.8ms tokenize                                                                                                                               \u2502\n\u2502    Total: 64.4ms, 2694 cells, 773.8 MB                                                                                                                                                     \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 \u2705 All 1 epochs completed                                                                                                                                                                  \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n", "type": "stream"}, {"name": "stdout", "text": "\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 \u2705 Prefetcher ready after 0.11s                                                                                                                                                            \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\ud83d\udd04 Epoch transition detected: -1 -> 0\n   Batch size 32: 780.9 MB (+17.7 MB)\n\n2. Performance with different settings:\n", "type": "stream"}, {"name": "stdout", "text": "\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 Prefetch batch 0 (epoch 0):                                                                                                                                                                \u2502\n\u2502    Lance loading: 16.8ms (51 batches, 415134 rows)                                                                                                                                         \u2502\n\u2502    Processing: 7.7ms window, 10.5ms shuffle, 25.4ms tokenize                                                                                                                               \u2502\n\u2502    Total: 63.8ms, 2694 cells, 791.9 MB                                                                                                                                                     \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 \u2705 All 1 epochs completed                                                                                                                                                                  \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n", "type": "stream"}, {"name": "stdout", "text": "\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 \u2705 Prefetcher ready after 0.10s                                                                                                                                                            \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\ud83d\udd04 Epoch transition detected: -1 -> 0\n   Small batches: 0.0011s for 3 batches\n", "type": "stream"}, {"name": "stdout", "text": "\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 Prefetch batch 0 (epoch 0):                                                                                                                                                                \u2502\n\u2502    Lance loading: 19.3ms (51 batches, 415134 rows)                                                                                                                                         \u2502\n\u2502    Processing: 9.8ms window, 10.0ms shuffle, 25.9ms tokenize                                                                                                                               \u2502\n\u2502    Total: 68.1ms, 2694 cells, 805.4 MB                                                                                                                                                     \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 \u2705 All 1 epochs completed                                                                                                                                                                  \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n", "type": "stream"}, {"name": "stdout", "text": "\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 \u2705 Prefetcher ready after 0.11s                                                                                                                                                            \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\ud83d\udd04 Epoch transition detected: -1 -> 0\n   Medium batches: 0.0010s for 3 batches\n", "type": "stream"}, {"name": "stdout", "text": "\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 Prefetch batch 0 (epoch 0):                                                                                                                                                                \u2502\n\u2502    Lance loading: 17.0ms (51 batches, 415134 rows)                                                                                                                                         \u2502\n\u2502    Processing: 7.7ms window, 10.4ms shuffle, 26.8ms tokenize                                                                                                                               \u2502\n\u2502    Total: 65.2ms, 2694 cells, 815.9 MB                                                                                                                                                     \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 \u2705 All 1 epochs completed                                                                                                                                                                  \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n", "type": "stream"}, {"name": "stdout", "text": "\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 \u2705 Prefetcher ready after 0.10s                                                                                                                                                            \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\ud83d\udd04 Epoch transition detected: -1 -> 0\n   Large batches: 0.0011s for 3 batches\n", "type": "stream"}], "id": "aLJB", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "8258f9bc568b2c9517ec0f036e28adba", "console": [], "id": "nHfw", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><h2 id=\"9-production-training-workflow\">9. Production Training Workflow</h2>\n<span class=\"paragraph\">Complete example of a production-ready training workflow:</span></span>"}, "type": "data"}]}, {"code_hash": "e8f9dd52afbf0caccf09c320401d5d13", "console": [{"name": "stdout", "text": "\ud83c\udfed Production Training Workflow\n========================================\n\u2705 Created tokenizer with 2000 total tokens\n", "type": "stream"}, {"name": "stdout", "text": "\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 Prefetch batch 0 (epoch 0):                                                                                                                                                                \u2502\n\u2502    Lance loading: 16.6ms (51 batches, 415134 rows)                                                                                                                                         \u2502\n\u2502    Processing: 8.7ms window, 10.3ms shuffle, 26.8ms tokenize                                                                                                                               \u2502\n\u2502    Total: 65.5ms, 2694 cells, 820.7 MB                                                                                                                                                     \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 \u2705 All 1 epochs completed                                                                                                                                                                  \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n", "type": "stream"}, {"name": "stdout", "text": "\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 \u2705 Prefetcher ready after 0.11s                                                                                                                                                            \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n", "type": "stream"}, {"name": "stdout", "text": "\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 Prefetch batch 0 (epoch 0):                                                                                                                                                                \u2502\n\u2502    Lance loading: 15.9ms (51 batches, 415134 rows)                                                                                                                                         \u2502\n\u2502    Processing: 10.9ms window, 11.1ms shuffle, 26.2ms tokenize                                                                                                                              \u2502\n\u2502    Total: 67.9ms, 2694 cells, 835.2 MB                                                                                                                                                     \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 \u2705 All 1 epochs completed                                                                                                                                                                  \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n", "type": "stream"}, {"name": "stdout", "text": "\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 \u2705 Prefetcher ready after 0.11s                                                                                                                                                            \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\n\ud83d\udcca Production Setup:\n   Batch size: 32\n   Max genes: 512\n\n\ud83e\uddea Testing production workflow:\n\ud83d\udd04 Epoch transition detected: -1 -> 0\n   Training batch shape: torch.Size([32, 2048])\n\ud83d\udd04 Epoch transition detected: -1 -> 0\n   Validation batch shape: torch.Size([32, 2048])\n", "type": "stream"}], "id": "xXTn", "outputs": [{"data": {"application/json": "[\"text/plain:<slaf.ml.dataloaders.SLAFDataLoader object at 0x2c9fa4b90>\", \"text/plain:<slaf.ml.dataloaders.SLAFDataLoader object at 0x2a73f9670>\", \"text/plain:<slaf.ml.tokenizers.SLAFTokenizer object at 0x2c9fa51c0>\"]"}, "type": "data"}]}, {"code_hash": "98cb4ee253ef5535efaafb4033272c74", "console": [], "id": "AjVT", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><h2 id=\"10-best-practices-for-ml-training\">10. Best Practices for ML Training</h2>\n<span class=\"paragraph\">Key best practices for using SLAF in ML training:</span></span>"}, "type": "data"}]}, {"code_hash": "b1e3273965c01f86c1b65fb715e2c6da", "console": [{"name": "stdout", "text": "\ud83d\udca1 Best Practices for ML Training\n========================================\n1. Tokenizer Configuration:\n   \u2705 Choose appropriate vocab_size based on your dataset\n   \u2705 Use n_expression_bins=50 for fine-grained expression modeling\n   \u2705 Use the correct tokenizer_type for your model architecture\n\n2. DataLoader Configuration:\n   \u2705 Start with small batch_size and increase gradually\n   \u2705 Use max_genes appropriate for your model architecture\n   \u2705 Set n_epochs for multi-epoch training on small datasets\n\n3. Performance Optimization:\n   \u2705 Fragment-based processing is much faster than SQL\n   \u2705 Use async prefetching to minimize GPU idle time\n   \u2705 Leverage device optimization for automatic tensor transfer\n   \u2705 Monitor memory usage during training\n\n4. Training Workflow:\n   \u2705 Create separate train/val/test splits\n   \u2705 Use consistent tokenizer across splits\n   \u2705 Implement proper error handling\n   \u2705 Use streaming datasets for large datasets\n\n5. Production Considerations:\n   \u2705 Use appropriate batch sizes for your hardware\n   \u2705 Implement checkpointing for long training runs\n   \u2705 Monitor tokenization throughput\n   \u2705 Consider distributed training for large datasets\n", "type": "stream"}], "id": "pHFh", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "9df763a6c9d9d091cba8e90096846ad4", "console": [], "id": "NCOB", "outputs": [{"data": {"text/html": "<span class=\"markdown prose dark:prose-invert\"><h2 id=\"summary\">Summary</h2>\n<span class=\"paragraph\"><strong>What you've learned about SLAF ML Training:</strong></span>\n<ol>\n<li><strong>Streaming DataLoader</strong>: Async prefetching with PyTorch compatibility</li>\n<li><strong>Tokenization Strategies</strong>: Geneformer and scGPT formats with optimized processing</li>\n<li><strong>Memory Efficiency</strong>: Streaming datasets for large-scale training</li>\n<li><strong>Production Workflow</strong>: Complete training pipeline setup</li>\n<li><strong>Best Practices</strong>: Guidelines for optimal ML training performance</li>\n</ol>\n<span class=\"paragraph\"><strong>Key Performance Improvements:</strong>\n- Fragment processing for high throughput\n- Streaming datasets with async prefetching\n- Automatic device optimization\n- Memory-efficient processing for large datasets</span></span>"}, "type": "data"}]}, {"code_hash": null, "console": [], "id": "aqbW", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}], "metadata": {"marimo_version": "0.14.0"}, "version": "1"},
            "runtimeConfig": null,
        };
    </script>

<marimo-code hidden="">
    import%20marimo%0A%0A__generated_with%20%3D%20%220.14.0%22%0Aapp%20%3D%20marimo.App(width%3D%22medium%22)%0A%0A%0A%40app.cell%0Adef%20_()%3A%0A%20%20%20%20import%20time%0A%0A%20%20%20%20import%20marimo%20as%20mo%0A%20%20%20%20import%20numpy%20as%20np%0A%0A%20%20%20%20from%20slaf%20import%20SLAFArray%0A%20%20%20%20from%20slaf.ml.dataloaders%20import%20SLAFDataLoader%0A%20%20%20%20from%20slaf.ml.tokenizers%20import%20SLAFTokenizer%0A%0A%20%20%20%20return%20SLAFArray%2C%20SLAFDataLoader%2C%20SLAFTokenizer%2C%20mo%2C%20np%2C%20time%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20%22%22%22%0A%20%20%20%20%23%20SLAF%20ML%20Training%20Pipeline%0A%0A%20%20%20%20This%20notebook%20demonstrates%20how%20to%20build%20complete%20ML%20training%20pipelines%20with%20SLAF%2C%20including%3A%0A%0A%20%20%20%20-%20Streaming%20DataLoader%20with%20async%20prefetching%0A%20%20%20%20-%20PyTorch-compatible%20datasets%0A%20%20%20%20-%20Performance%20optimization%20techniques%0A%20%20%20%20-%20Custom%20training%20loop%20examples%0A%0A%20%20%20%20**Key%20Benefits%20for%20ML%20Training%3A**%0A%0A%20%20%20%20%F0%9F%92%BE%20**Memory%20Efficient**%3A%20Stream%20data%20in%20chunks%20without%20loading%20everything%20into%20memory%0A%0A%20%20%20%20%F0%9F%94%84%20**Flexible**%3A%20Support%20for%20different%20tokenization%20strategies%20(scGPT%2C%20Geneformer)%0A%0A%20%20%20%20%F0%9F%A7%AC%20**High%20Throughput**%3A%20Load%20and%20tokenize%20cells%20at%2010k%20cells%20%2F%20sec%3A%20fast%20enough%20to%20never%20let%20a%208%20x%20H100%20GPU%20node%20stay%20idle%0A%20%20%20%20%22%22%22%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(SLAFArray)%3A%0A%20%20%20%20%23%20Load%20SLAF%20dataset%20for%20ML%20examples%0A%20%20%20%20slaf%20%3D%20SLAFArray(%22..%2Fslaf-datasets%2Fpbmc3k_processed.slaf%22)%0A%20%20%20%20print(f%22%E2%9C%85%20Loaded%20SLAF%20dataset%3A%20%7Bslaf.shape%5B0%5D%3A%2C%7D%20cells%20%C3%97%20%7Bslaf.shape%5B1%5D%3A%2C%7D%20genes%22)%0A%0A%20%20%20%20%23%20Show%20dataset%20info%0A%20%20%20%20slaf.info()%0A%20%20%20%20return%20(slaf%2C)%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20%22%22%22%0A%20%20%20%20%23%23%202.%20Tokenization%20Strategies%0A%0A%20%20%20%20SLAF%20supports%20different%20tokenization%20strategies%20for%20different%20model%20architectures.%0A%20%20%20%20Each%20strategy%20has%20its%20own%20format%20and%20vocabulary%20structure%3A%0A%20%20%20%20%22%22%22%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20%22%22%22%0A%20%20%20%20%23%23%23%20GeneFormer%20vs%20scGPT%20Tokenization%0A%0A%20%20%20%20**GeneFormer**%3A%20Simple%20gene%20sequences%20sorted%20by%20expression%0A%20%20%20%20-%20Format%3A%20%60%5BCLS%2C%20gene1%2C%20gene2%2C%20gene3%2C%20...%2C%20SEP%5D%60%0A%20%20%20%20-%20Vocabulary%3A%20Gene%20tokens%20only%0A%20%20%20%20-%20Use%20case%3A%20Models%20that%20only%20need%20gene%20identity%0A%0A%20%20%20%20**scGPT**%3A%20Gene-expression%20pairs%20with%20special%20tokens%0A%20%20%20%20-%20Format%3A%20%60%5BCLS%2C%20gene1%2C%20expr1%2C%20gene2%2C%20expr2%2C%20...%2C%20SEP%5D%60%0A%20%20%20%20-%20Vocabulary%3A%20Gene%20tokens%20%2B%20expression%20bin%20tokens%0A%20%20%20%20-%20Use%20case%3A%20Models%20that%20need%20both%20gene%20identity%20and%20expression%20levels%0A%20%20%20%20%22%22%22%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(SLAFTokenizer%2C%20slaf)%3A%0A%20%20%20%20def%20create_tokenizer()%3A%0A%20%20%20%20%20%20%20%20%23%20Create%20tokenizer%20with%20custom%20settings%0A%20%20%20%20%20%20%20%20tokenizer%20%3D%20SLAFTokenizer(%0A%20%20%20%20%20%20%20%20%20%20%20%20slaf_array%3Dslaf%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20vocab_size%3D2000%2C%20%20%23%20Dataset%20has%20%3C2000%20genes%0A%20%20%20%20%20%20%20%20%20%20%20%20n_expression_bins%3D20%2C%20%20%23%20More%20expression%20bins%0A%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20%23%20Get%20vocabulary%20information%0A%20%20%20%20%20%20%20%20vocab_info%20%3D%20tokenizer.get_vocab_info()%0A%20%20%20%20%20%20%20%20print(%22%E2%9C%85%20Tokenizer%20initialized%3A%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20Total%20vocabulary%20size%3A%20%7Bvocab_info%5B'vocab_size'%5D%3A%2C%7D%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20Special%20tokens%3A%20%7Bvocab_info%5B'special_tokens'%5D%7D%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20Expression%20bins%3A%20%7Bvocab_info%5B'n_expression_bins'%5D%7D%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20Gene%20vocabulary%20size%3A%20%7Bvocab_info%5B'gene_vocab_size'%5D%3A%2C%7D%22)%0A%0A%20%20%20%20%20%20%20%20%23%20Show%20special%20tokens%0A%20%20%20%20%20%20%20%20print(%22%5CnSpecial%20tokens%3A%22)%0A%20%20%20%20%20%20%20%20for%20token_name%2C%20token_id%20in%20tokenizer.special_tokens.items()%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%20%20%20%7Btoken_name%7D%3A%20%7Btoken_id%7D%22)%0A%0A%20%20%20%20%20%20%20%20return%20tokenizer%0A%0A%20%20%20%20tokenizer%20%3D%20create_tokenizer()%0A%20%20%20%20return%20(tokenizer%2C)%0A%0A%0A%40app.cell%0Adef%20_(SLAFTokenizer%2C%20slaf)%3A%0A%20%20%20%20def%20demonstrate_geneformer()%3A%0A%20%20%20%20%20%20%20%20print(%22%F0%9F%A7%AC%20GeneFormer%20Tokenization%20%26%20Decoding%22)%0A%20%20%20%20%20%20%20%20print(%22%3D%22%20*%2040)%0A%0A%20%20%20%20%20%20%20%20%23%20Create%20GeneFormer%20tokenizer%0A%20%20%20%20%20%20%20%20tokenizer%20%3D%20SLAFTokenizer(%0A%20%20%20%20%20%20%20%20%20%20%20%20slaf_array%3Dslaf%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20tokenizer_type%3D%22geneformer%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20vocab_size%3D2000%2C%20%20%23%20Dataset%20has%20%3C2000%20genes%0A%20%20%20%20%20%20%20%20%20%20%20%20n_expression_bins%3D20%2C%0A%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20%23%20Show%20vocabulary%20info%0A%20%20%20%20%20%20%20%20vocab_info%20%3D%20tokenizer.get_vocab_info()%0A%20%20%20%20%20%20%20%20print(%0A%20%20%20%20%20%20%20%20%20%20%20%20f%22%E2%9C%85%20Vocabulary%3A%20%7Bvocab_info%5B'vocab_size'%5D%7D%20total%20tokens%2C%20%7Bvocab_info%5B'gene_vocab_size'%5D%7D%20genes%22%0A%20%20%20%20%20%20%20%20)%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20Special%20tokens%3A%20%7Bvocab_info%5B'special_tokens'%5D%7D%22)%0A%0A%20%20%20%20%20%20%20%20%23%20Create%20sample%20gene%20sequences%0A%20%20%20%20%20%20%20%20gene_sequences%20%3D%20%5B%5B0%2C%201%2C%202%2C%203%2C%204%5D%2C%20%5B1%2C%202%2C%203%2C%204%2C%205%5D%2C%20%5B0%2C%202%2C%204%2C%206%2C%208%5D%5D%0A%0A%20%20%20%20%20%20%20%20%23%20Tokenize%0A%20%20%20%20%20%20%20%20input_ids%2C%20attention_mask%20%3D%20tokenizer.tokenize(%0A%20%20%20%20%20%20%20%20%20%20%20%20gene_sequences%3Dgene_sequences%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20max_genes%3D50%2C%0A%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20print(%22%5Cn%F0%9F%93%8A%20Tokenization%20Results%3A%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20Input%20shape%3A%20%7Binput_ids.shape%7D%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20Attention%20mask%20shape%3A%20%7Battention_mask.shape%7D%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20First%20sequence%20tokens%3A%20%7Binput_ids%5B0%5D.tolist()%5B%3A10%5D%7D...%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20First%20sequence%20attention%3A%20%7Battention_mask%5B0%5D.tolist()%5B%3A10%5D%7D...%22)%0A%0A%20%20%20%20%20%20%20%20%23%20Decode%20first%20sequence%0A%20%20%20%20%20%20%20%20print(%22%5Cn%F0%9F%94%8D%20Decoding%20Results%3A%22)%0A%20%20%20%20%20%20%20%20decoded%20%3D%20tokenizer.decode_tokens(input_ids%5B0%5D.tolist())%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20Sequence%20length%3A%20%7Blen(input_ids%5B0%5D)%7D%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20Genes%3A%20%7Blen(decoded%5B'genes'%5D)%7D%20genes%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20First%20few%20genes%3A%20%7Bdecoded%5B'genes'%5D%5B%3A5%5D%7D%22)%0A%0A%20%20%20%20%20%20%20%20return%20tokenizer%2C%20input_ids%2C%20attention_mask%0A%0A%20%20%20%20geneformer_tokenizer%2C%20geneformer_input_ids%2C%20geneformer_attention_mask%20%3D%20(%0A%20%20%20%20%20%20%20%20demonstrate_geneformer()%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(SLAFTokenizer%2C%20slaf)%3A%0A%20%20%20%20def%20demonstrate_scgpt()%3A%0A%20%20%20%20%20%20%20%20print(%22%F0%9F%A7%AC%20scGPT%20Tokenization%20%26%20Decoding%22)%0A%20%20%20%20%20%20%20%20print(%22%3D%22%20*%2040)%0A%0A%20%20%20%20%20%20%20%20%23%20Create%20scGPT%20tokenizer%0A%20%20%20%20%20%20%20%20tokenizer%20%3D%20SLAFTokenizer(%0A%20%20%20%20%20%20%20%20%20%20%20%20slaf_array%3Dslaf%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20tokenizer_type%3D%22scgpt%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20vocab_size%3D2000%2C%20%20%23%20Dataset%20has%20%3C2000%20genes%0A%20%20%20%20%20%20%20%20%20%20%20%20n_expression_bins%3D20%2C%0A%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20%23%20Show%20vocabulary%20info%0A%20%20%20%20%20%20%20%20vocab_info%20%3D%20tokenizer.get_vocab_info()%0A%20%20%20%20%20%20%20%20print(%0A%20%20%20%20%20%20%20%20%20%20%20%20f%22%E2%9C%85%20Vocabulary%3A%20%7Bvocab_info%5B'vocab_size'%5D%7D%20total%20tokens%2C%20%7Bvocab_info%5B'gene_vocab_size'%5D%7D%20genes%22%0A%20%20%20%20%20%20%20%20)%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20Special%20tokens%3A%20%7Bvocab_info%5B'special_tokens'%5D%7D%22)%0A%20%20%20%20%20%20%20%20print(%0A%20%20%20%20%20%20%20%20%20%20%20%20f%22%20%20%20Expression%20bins%3A%20%7Bvocab_info%5B'n_expression_bins'%5D%7D%20bins%20(start%20at%20token%20%7Btokenizer.expr_bin_start%7D)%22%0A%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20%23%20Create%20sample%20gene%20and%20expression%20sequences%0A%20%20%20%20%20%20%20%20gene_sequences%20%3D%20%5B%5B0%2C%201%2C%202%5D%2C%20%5B1%2C%202%2C%203%5D%5D%0A%20%20%20%20%20%20%20%20expr_sequences%20%3D%20%5B%5B0.5%2C%200.8%2C%200.2%5D%2C%20%5B0.9%2C%200.1%2C%200.7%5D%5D%0A%0A%20%20%20%20%20%20%20%20%23%20Tokenize%0A%20%20%20%20%20%20%20%20input_ids%2C%20attention_mask%20%3D%20tokenizer.tokenize(%0A%20%20%20%20%20%20%20%20%20%20%20%20gene_sequences%3Dgene_sequences%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20expr_sequences%3Dexpr_sequences%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20max_genes%3D25%2C%0A%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20print(%22%5Cn%F0%9F%93%8A%20Tokenization%20Results%3A%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20Input%20shape%3A%20%7Binput_ids.shape%7D%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20Attention%20mask%20shape%3A%20%7Battention_mask.shape%7D%22)%0A%20%20%20%20%20%20%20%20print(%22%20%20%20Expected%20length%3A%201%20%2B%202*25%20%2B%201%20%3D%2052%20(CLS%20%2B%2025*(gene%2Bexpr)%20%2B%20SEP)%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20First%20sequence%20tokens%3A%20%7Binput_ids%5B0%5D.tolist()%5B%3A10%5D%7D...%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20First%20sequence%20attention%3A%20%7Battention_mask%5B0%5D.tolist()%5B%3A10%5D%7D...%22)%0A%0A%20%20%20%20%20%20%20%20%23%20Decode%20first%20sequence%0A%20%20%20%20%20%20%20%20print(%22%5Cn%F0%9F%94%8D%20Decoding%20Results%3A%22)%0A%20%20%20%20%20%20%20%20decoded%20%3D%20tokenizer.decode_tokens(input_ids%5B0%5D.tolist())%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20Sequence%20length%3A%20%7Blen(input_ids%5B0%5D)%7D%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20Genes%3A%20%7Blen(decoded%5B'genes'%5D)%7D%20genes%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20Expressions%3A%20%7Blen(decoded%5B'expressions'%5D)%7D%20expressions%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20First%20few%20genes%3A%20%7Bdecoded%5B'genes'%5D%5B%3A3%5D%7D%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20First%20few%20expressions%3A%20%7Bdecoded%5B'expressions'%5D%5B%3A3%5D%7D%22)%0A%0A%20%20%20%20%20%20%20%20return%20tokenizer%2C%20input_ids%2C%20attention_mask%0A%0A%20%20%20%20scgpt_tokenizer%2C%20scgpt_input_ids%2C%20scgpt_attention_mask%20%3D%20demonstrate_scgpt()%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20%22%22%22%0A%20%20%20%20%23%23%203.%20SLAF%20DataLoader%20-%20Production-Ready%20Training%0A%0A%20%20%20%20SLAF%20provides%20a%20high-performance%20DataLoader%20with%20streaming%20and%20async%20prefetching%3A%0A%20%20%20%20%22%22%22%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%23%23%23%20DataLoader%20Configuration%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(SLAFDataLoader%2C%20slaf)%3A%0A%20%20%20%20def%20create_dataloader()%3A%0A%20%20%20%20%20%20%20%20%23%20Initialize%20DataLoader%0A%20%20%20%20%20%20%20%20print(%22%F0%9F%93%A6%20SLAF%20DataLoader%20Configuration%22)%0A%20%20%20%20%20%20%20%20print(%22%3D%22%20*%2040)%0A%0A%20%20%20%20%20%20%20%20%23%20Create%20DataLoader%20with%20custom%20settings%0A%20%20%20%20%20%20%20%20dataloader%20%3D%20SLAFDataLoader(%0A%20%20%20%20%20%20%20%20%20%20%20%20slaf_array%3Dslaf%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20tokenizer_type%3D%22geneformer%22%2C%20%20%23%20or%20%22scgpt%22%0A%20%20%20%20%20%20%20%20%20%20%20%20batch_size%3D16%2C%20%20%23%20Small%20batch%20for%20demo%0A%20%20%20%20%20%20%20%20%20%20%20%20max_genes%3D100%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20vocab_size%3D2000%2C%20%20%23%20Dataset%20has%20%3C2000%20genes%0A%20%20%20%20%20%20%20%20%20%20%20%20n_expression_bins%3D20%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20n_epochs%3D1%2C%20%20%23%20Number%20of%20epochs%0A%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20print(%22%E2%9C%85%20DataLoader%20initialized%3A%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20Tokenizer%20type%3A%20%7Bdataloader.tokenizer_type%7D%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20Batch%20size%3A%20%7Bdataloader.batch_size%7D%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20Max%20genes%3A%20%7Bdataloader.max_genes%7D%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20Special%20tokens%3A%20%7Bdataloader.special_tokens%7D%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20Number%20of%20epochs%3A%20%7Bdataloader.n_epochs%7D%22)%0A%0A%20%20%20%20%20%20%20%20return%20dataloader%0A%0A%20%20%20%20create_dataloader()%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%23%23%23%20DataLoader%20Iteration%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(SLAFDataLoader%2C%20slaf)%3A%0A%20%20%20%20def%20demonstrate_dataloader_iteration()%3A%0A%20%20%20%20%20%20%20%20%23%20Demonstrate%20DataLoader%20iteration%0A%20%20%20%20%20%20%20%20print(%22%F0%9F%94%84%20DataLoader%20Iteration%22)%0A%20%20%20%20%20%20%20%20print(%22%3D%22%20*%2025)%0A%0A%20%20%20%20%20%20%20%20%23%20Create%20dataloader%0A%20%20%20%20%20%20%20%20dataloader%20%3D%20SLAFDataLoader(%0A%20%20%20%20%20%20%20%20%20%20%20%20slaf_array%3Dslaf%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20tokenizer_type%3D%22geneformer%22%2C%20%20%23%20or%20%22scgpt%22%0A%20%20%20%20%20%20%20%20%20%20%20%20batch_size%3D16%2C%20%20%23%20Small%20batch%20for%20demo%0A%20%20%20%20%20%20%20%20%20%20%20%20max_genes%3D100%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20vocab_size%3D2000%2C%20%20%23%20Dataset%20has%20%3C2000%20genes%0A%20%20%20%20%20%20%20%20%20%20%20%20n_expression_bins%3D20%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20n_epochs%3D1%2C%20%20%23%20Number%20of%20epochs%0A%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20%23%20Get%20first%20batch%0A%20%20%20%20%20%20%20%20print(%221.%20First%20batch%20structure%3A%22)%0A%20%20%20%20%20%20%20%20batch%20%3D%20next(iter(dataloader))%0A%0A%20%20%20%20%20%20%20%20for%20key%2C%20value%20in%20batch.items()%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20hasattr(value%2C%20%22shape%22)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%20%20%20%7Bkey%7D%3A%20%7Btype(value)%7D%20with%20shape%20%7Bvalue.shape%7D%22)%0A%20%20%20%20%20%20%20%20%20%20%20%20else%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%20%20%20%7Bkey%7D%3A%20%7Btype(value)%7D%20with%20length%20%7Blen(value)%7D%22)%0A%0A%20%20%20%20%20%20%20%20%23%20Show%20batch%20details%0A%20%20%20%20%20%20%20%20input_ids%20%3D%20batch%5B%22input_ids%22%5D%0A%20%20%20%20%20%20%20%20attention_mask%20%3D%20batch%5B%22attention_mask%22%5D%0A%20%20%20%20%20%20%20%20cell_ids%20%3D%20batch%5B%22cell_ids%22%5D%0A%0A%20%20%20%20%20%20%20%20print(%22%5Cn2.%20Batch%20details%3A%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20Input%20IDs%20shape%3A%20%7Binput_ids.shape%7D%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20Attention%20mask%20shape%3A%20%7Battention_mask.shape%7D%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20Cell%20IDs%20shape%3A%20%7Bcell_ids.shape%7D%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20Data%20type%3A%20%7Binput_ids.dtype%7D%22)%0A%0A%20%20%20%20%20%20%20%20%23%20Show%20sample%20tokens%0A%20%20%20%20%20%20%20%20print(%22%5Cn3.%20Sample%20tokens%20from%20first%20sequence%3A%22)%0A%20%20%20%20%20%20%20%20first_seq%20%3D%20input_ids%5B0%5D%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20First%2010%20tokens%3A%20%7Bfirst_seq%5B%3A10%5D.tolist()%7D%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20Sequence%20length%3A%20%7Blen(first_seq)%7D%22)%0A%0A%20%20%20%20demonstrate_dataloader_iteration()%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%23%23%23%20Performance%20Testing%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(SLAFDataLoader%2C%20slaf%2C%20time)%3A%0A%20%20%20%20def%20test_dataloader_performance()%3A%0A%20%20%20%20%20%20%20%20%23%20Performance%20testing%20of%20DataLoader%0A%20%20%20%20%20%20%20%20print(%22%E2%9A%A1%20DataLoader%20Performance%22)%0A%20%20%20%20%20%20%20%20print(%22%3D%22%20*%2030)%0A%0A%20%20%20%20%20%20%20%20%23%20Create%20dataloader%0A%20%20%20%20%20%20%20%20dataloader%20%3D%20SLAFDataLoader(%0A%20%20%20%20%20%20%20%20%20%20%20%20slaf_array%3Dslaf%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20tokenizer_type%3D%22geneformer%22%2C%20%20%23%20or%20%22scgpt%22%0A%20%20%20%20%20%20%20%20%20%20%20%20batch_size%3D16%2C%20%20%23%20Small%20batch%20for%20demo%0A%20%20%20%20%20%20%20%20%20%20%20%20max_genes%3D100%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20vocab_size%3D2000%2C%20%20%23%20Dataset%20has%20%3C2000%20genes%0A%20%20%20%20%20%20%20%20%20%20%20%20n_expression_bins%3D20%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20n_epochs%3D1%2C%20%20%23%20Number%20of%20epochs%0A%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20%23%20Test%20iteration%20speed%0A%20%20%20%20%20%20%20%20print(%221.%20Iteration%20performance%3A%22)%0A%0A%20%20%20%20%20%20%20%20batch_count%20%3D%200%0A%20%20%20%20%20%20%20%20total_tokens%20%3D%200%0A%0A%20%20%20%20%20%20%20%20start_time%20%3D%20time.time()%0A%20%20%20%20%20%20%20%20for%20batch%20in%20dataloader%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20batch_count%20%2B%3D%201%0A%20%20%20%20%20%20%20%20%20%20%20%20total_tokens%20%2B%3D%20batch%5B%22input_ids%22%5D.shape%5B0%5D%20*%20batch%5B%22input_ids%22%5D.shape%5B1%5D%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Only%20process%20first%20few%20batches%20for%20demo%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20batch_count%20%3E%3D%205%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20break%0A%0A%20%20%20%20%20%20%20%20elapsed_time%20%3D%20time.time()%20-%20start_time%0A%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20Processed%20%7Bbatch_count%7D%20batches%20in%20%7Belapsed_time%3A.4f%7Ds%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20Total%20tokens%3A%20%7Btotal_tokens%3A%2C%7D%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20Tokens%20per%20second%3A%20%7Btotal_tokens%20%2F%20elapsed_time%3A%2C.0f%7D%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20Batches%20per%20second%3A%20%7Bbatch_count%20%2F%20elapsed_time%3A.2f%7D%22)%0A%0A%20%20%20%20test_dataloader_performance()%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20%22%22%22%0A%20%20%20%20%23%23%205.%20PyTorch%20Training%20Loop%20Integration%0A%0A%20%20%20%20Here's%20how%20to%20integrate%20SLAF%20DataLoader%20with%20PyTorch%20training%3A%0A%20%20%20%20%22%22%22%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(SLAFDataLoader%2C%20slaf)%3A%0A%20%20%20%20def%20demonstrate_pytorch_integration()%3A%0A%20%20%20%20%20%20%20%20%23%20Demonstrate%20PyTorch%20integration%0A%20%20%20%20%20%20%20%20print(%22%F0%9F%94%A5%20PyTorch%20Training%20Loop%20Integration%22)%0A%20%20%20%20%20%20%20%20print(%22%3D%22%20*%2045)%0A%0A%20%20%20%20%20%20%20%20%23%20Reinitialize%20DataLoader%20since%20the%20previous%20one%20was%20exhausted%0A%20%20%20%20%20%20%20%20dataloader%20%3D%20SLAFDataLoader(%0A%20%20%20%20%20%20%20%20%20%20%20%20slaf_array%3Dslaf%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20tokenizer_type%3D%22geneformer%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20batch_size%3D16%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20max_genes%3D100%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20vocab_size%3D2000%2C%20%20%23%20Dataset%20has%20%3C2000%20genes%0A%20%20%20%20%20%20%20%20%20%20%20%20n_expression_bins%3D20%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20n_epochs%3D1%2C%0A%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20%23%20Check%20if%20PyTorch%20is%20available%0A%20%20%20%20%20%20%20%20try%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20import%20torch%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20TORCH_AVAILABLE%20%3D%20True%0A%20%20%20%20%20%20%20%20%20%20%20%20print(%22%E2%9C%85%20PyTorch%20is%20available%22)%0A%20%20%20%20%20%20%20%20except%20ImportError%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20TORCH_AVAILABLE%20%3D%20False%0A%20%20%20%20%20%20%20%20%20%20%20%20print(%22%E2%9A%A0%EF%B8%8F%20PyTorch%20not%20available%20-%20showing%20numpy-based%20approach%22)%0A%0A%20%20%20%20%20%20%20%20if%20TORCH_AVAILABLE%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20print(%22%5Cn1.%20PyTorch%20tensor%20conversion%3A%22)%0A%20%20%20%20%20%20%20%20%20%20%20%20batch%20%3D%20next(iter(dataloader))%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Get%20device%20info%0A%20%20%20%20%20%20%20%20%20%20%20%20from%20slaf.ml.dataloaders%20import%20get_device_info%2C%20get_optimal_device%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20device_info%20%3D%20get_device_info()%0A%20%20%20%20%20%20%20%20%20%20%20%20optimal_device%20%3D%20get_optimal_device()%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%20%20%20Device%20info%3A%20%7Bdevice_info%7D%22)%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%20%20%20Using%20device%3A%20%7Boptimal_device%7D%22)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Convert%20to%20PyTorch%20tensors%20on%20optimal%20device%0A%20%20%20%20%20%20%20%20%20%20%20%20input_ids_tensor%20%3D%20torch.tensor(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20batch%5B%22input_ids%22%5D%2C%20dtype%3Dtorch.long%2C%20device%3Doptimal_device%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%20%20%20%20%20%20%20%20%20%20%20%20attention_mask_tensor%20%3D%20torch.tensor(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20batch%5B%22attention_mask%22%5D%2C%20dtype%3Dtorch.bool%2C%20device%3Doptimal_device%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%20%20%20%20%20%20%20%20%20%20%20%20cell_ids_tensor%20%3D%20torch.tensor(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20batch%5B%22cell_ids%22%5D%2C%20dtype%3Dtorch.long%2C%20device%3Doptimal_device%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20print(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20f%22%20%20%20Input%20IDs%20tensor%3A%20%7Binput_ids_tensor.shape%7D%2C%20%7Binput_ids_tensor.dtype%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%20%20%20%20%20%20%20%20%20%20%20%20print(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20f%22%20%20%20Attention%20mask%20tensor%3A%20%7Battention_mask_tensor.shape%7D%2C%20%7Battention_mask_tensor.dtype%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%20%20%20%20%20%20%20%20%20%20%20%20print(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20f%22%20%20%20Cell%20IDs%20tensor%3A%20%7Bcell_ids_tensor.shape%7D%2C%20%7Bcell_ids_tensor.dtype%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20print(%22%5Cn2.%20Simple%20training%20loop%20structure%3A%22)%0A%20%20%20%20%20%20%20%20%20%20%20%20print(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Training%20loop%20example%20with%20smart%20device%20detection%0A%20%20%20%20%20%20%20%20%20%20%20%20from%20slaf.ml.dataloaders%20import%20get_optimal_device%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20device%20%3D%20get_optimal_device()%0A%20%20%20%20%20%20%20%20%20%20%20%20model%20%3D%20YourModel(vocab_size%3Dtokenizer.get_vocab_info()%5B'vocab_size'%5D)%0A%20%20%20%20%20%20%20%20%20%20%20%20model%20%3D%20model.to(device)%20%20%23%20Move%20model%20to%20optimal%20device%0A%20%20%20%20%20%20%20%20%20%20%20%20optimizer%20%3D%20torch.optim.AdamW(model.parameters()%2C%20lr%3D1e-4)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20for%20epoch%20in%20range(num_epochs)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20model.train()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20for%20batch%20in%20dataloader%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20DataLoader%20already%20provides%20tensors%20on%20optimal%20device%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20input_ids%20%3D%20batch%5B%22input_ids%22%5D%20%20%23%20Already%20on%20device%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20attention_mask%20%3D%20batch%5B%22attention_mask%22%5D%20%20%23%20Already%20on%20device%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Forward%20pass%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20outputs%20%3D%20model(input_ids%3Dinput_ids%2C%20attention_mask%3Dattention_mask)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20loss%20%3D%20outputs.loss%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Backward%20pass%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20optimizer.zero_grad()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20loss.backward()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20optimizer.step()%0A%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20else%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20print(%22%5Cn1.%20Numpy-based%20approach%3A%22)%0A%20%20%20%20%20%20%20%20%20%20%20%20batch%20%3D%20next(iter(dataloader))%0A%20%20%20%20%20%20%20%20%20%20%20%20print(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20f%22%20%20%20Input%20IDs%3A%20%7Bbatch%5B'input_ids'%5D.shape%7D%2C%20%7Bbatch%5B'input_ids'%5D.dtype%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%20%20%20%20%20%20%20%20%20%20%20%20print(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20f%22%20%20%20Attention%20mask%3A%20%7Bbatch%5B'attention_mask'%5D.shape%7D%2C%20%7Bbatch%5B'attention_mask'%5D.dtype%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%20%20%20Cell%20IDs%3A%20%7Bbatch%5B'cell_ids'%5D.shape%7D%2C%20%7Bbatch%5B'cell_ids'%5D.dtype%7D%22)%0A%0A%20%20%20%20demonstrate_pytorch_integration()%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20%22%22%22%0A%20%20%20%20%23%23%206.%20Streaming%20Dataset%20Features%0A%0A%20%20%20%20Learn%20about%20the%20new%20streaming%20dataset%20capabilities%3A%0A%20%20%20%20%22%22%22%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%23%23%23%20Async%20Prefetching%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(SLAFDataLoader%2C%20slaf)%3A%0A%20%20%20%20def%20demonstrate_streaming_features()%3A%0A%20%20%20%20%20%20%20%20print(%22%F0%9F%94%84%20Streaming%20Dataset%20Features%22)%0A%20%20%20%20%20%20%20%20print(%22%3D%22%20*%2035)%0A%0A%20%20%20%20%20%20%20%20%23%20Create%20dataloader%20with%20streaming%20features%0A%20%20%20%20%20%20%20%20dataloader%20%3D%20SLAFDataLoader(%0A%20%20%20%20%20%20%20%20%20%20%20%20slaf_array%3Dslaf%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20tokenizer_type%3D%22geneformer%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20batch_size%3D8%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20max_genes%3D50%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20n_epochs%3D1%2C%20%20%23%20Single%20epoch%20for%20demo%0A%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20print(%22%E2%9C%85%20Streaming%20features%3A%22)%0A%20%20%20%20%20%20%20%20print(%22%20%20%20-%20Async%20fragment%20prefetching%22)%0A%20%20%20%20%20%20%20%20print(%22%20%20%20-%20Background%20fragment%20loading%22)%0A%20%20%20%20%20%20%20%20print(%22%20%20%20-%20Memory-efficient%20streaming%22)%0A%20%20%20%20%20%20%20%20print(%22%20%20%20-%20PyTorch%20IterableDataset%20compatibility%22)%0A%0A%20%20%20%20%20%20%20%20%23%20Test%20streaming%20iteration%0A%20%20%20%20%20%20%20%20print(%22%5Cn%F0%9F%94%84%20Testing%20streaming%20iteration%3A%22)%0A%20%20%20%20%20%20%20%20batch_count%20%3D%200%0A%20%20%20%20%20%20%20%20for%20batch%20in%20dataloader%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20batch_count%20%2B%3D%201%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%20%20%20Batch%20%7Bbatch_count%7D%3A%20%7Bbatch%5B'input_ids'%5D.shape%7D%22)%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20batch_count%20%3E%3D%203%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20break%0A%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20Successfully%20streamed%20%7Bbatch_count%7D%20batches%22)%0A%0A%20%20%20%20demonstrate_streaming_features()%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%23%23%23%20Device%20Optimization%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(SLAFDataLoader%2C%20slaf)%3A%0A%20%20%20%20def%20demonstrate_device_optimization()%3A%0A%20%20%20%20%20%20%20%20print(%22%E2%9A%A1%20Device%20Optimization%22)%0A%20%20%20%20%20%20%20%20print(%22%3D%22%20*%2025)%0A%0A%20%20%20%20%20%20%20%20from%20slaf.ml.dataloaders%20import%20get_device_info%2C%20get_optimal_device%0A%0A%20%20%20%20%20%20%20%20%23%20Get%20device%20information%0A%20%20%20%20%20%20%20%20device_info%20%3D%20get_device_info()%0A%20%20%20%20%20%20%20%20optimal_device%20%3D%20get_optimal_device()%0A%0A%20%20%20%20%20%20%20%20print(%22%E2%9C%85%20Device%20detection%3A%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20PyTorch%20available%3A%20%7Bdevice_info%5B'torch_available'%5D%7D%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20CUDA%20available%3A%20%7Bdevice_info%5B'cuda_available'%5D%7D%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20MPS%20available%3A%20%7Bdevice_info%5B'mps_available'%5D%7D%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20Optimal%20device%3A%20%7Boptimal_device%7D%22)%0A%0A%20%20%20%20%20%20%20%20%23%20Create%20dataloader%20with%20device%20optimization%0A%20%20%20%20%20%20%20%20dataloader%20%3D%20SLAFDataLoader(%0A%20%20%20%20%20%20%20%20%20%20%20%20slaf_array%3Dslaf%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20tokenizer_type%3D%22geneformer%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20batch_size%3D8%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20max_genes%3D50%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20n_epochs%3D1%2C%0A%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20print(%22%5Cn%E2%9C%85%20Device%20optimization%3A%22)%0A%20%20%20%20%20%20%20%20print(%22%20%20%20-%20Automatic%20device%20detection%22)%0A%20%20%20%20%20%20%20%20print(%22%20%20%20-%20Tensor%20transfer%20to%20optimal%20device%22)%0A%20%20%20%20%20%20%20%20print(%22%20%20%20-%20Memory-efficient%20device%20handling%22)%0A%0A%20%20%20%20%20%20%20%20%23%20Test%20device%20transfer%0A%20%20%20%20%20%20%20%20batch%20%3D%20next(iter(dataloader))%0A%20%20%20%20%20%20%20%20if%20hasattr(batch%5B%22input_ids%22%5D%2C%20%22device%22)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%20%20%20Batch%20device%3A%20%7Bbatch%5B'input_ids'%5D.device%7D%22)%0A%0A%20%20%20%20demonstrate_device_optimization()%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20%22%22%22%0A%20%20%20%20%23%23%207.%20Advanced%20Tokenization%20Features%0A%0A%20%20%20%20Explore%20advanced%20tokenization%20features%20and%20optimizations%3A%0A%20%20%20%20%22%22%22%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(SLAFTokenizer%2C%20np%2C%20time%2C%20tokenizer)%3A%0A%20%20%20%20def%20demonstrate_advanced_features()%3A%0A%20%20%20%20%20%20%20%20%23%20Advanced%20tokenization%20features%0A%20%20%20%20%20%20%20%20print(%22%F0%9F%9A%80%20Advanced%20Tokenization%20Features%22)%0A%20%20%20%20%20%20%20%20print(%22%3D%22%20*%2040)%0A%0A%20%20%20%20%20%20%20%20print(%221.%20Different%20max_genes%20settings%3A%22)%0A%20%20%20%20%20%20%20%20gene_sequences%20%3D%20%5B%5Bi%2C%20i%20%2B%201%2C%20i%20%2B%202%5D%20for%20i%20in%20range(20)%5D%0A%0A%20%20%20%20%20%20%20%20for%20max_genes%20in%20%5B25%2C%2050%2C%20100%5D%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20input_ids%2C%20attention_mask%20%3D%20tokenizer.tokenize(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20gene_sequences%3Dgene_sequences%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20max_genes%3Dmax_genes%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%20%20%20%20%20%20%20%20%20%20%20%20avg_length%20%3D%20np.mean(%5Blen(seq)%20for%20seq%20in%20input_ids%5D)%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%20%20%20max_genes%3D%7Bmax_genes%7D%3A%20avg_length%3D%7Bavg_length%3A.1f%7D%22)%0A%0A%20%20%20%20%20%20%20%20print(%22%5Cn2.%20Different%20vocabulary%20sizes%3A%22)%0A%20%20%20%20%20%20%20%20for%20vocab_size%20in%20%5B1000%2C%205000%2C%2010000%5D%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Create%20a%20new%20tokenizer%20with%20different%20vocab%20size%0A%20%20%20%20%20%20%20%20%20%20%20%20test_tokenizer%20%3D%20SLAFTokenizer(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20slaf_array%3Dtokenizer.slaf_array%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20vocab_size%3Dvocab_size%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20n_expression_bins%3D10%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%20%20%20%20%20%20%20%20%20%20%20%20vocab_info%20%3D%20test_tokenizer.get_vocab_info()%0A%20%20%20%20%20%20%20%20%20%20%20%20print(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20f%22%20%20%20vocab_size%3D%7Bvocab_size%7D%3A%20actual_vocab%3D%7Bvocab_info%5B'vocab_size'%5D%7D%22%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20print(%22%5Cn3.%20Expression%20binning%20for%20scGPT%3A%22)%0A%20%20%20%20%20%20%20%20%23%20Test%20scGPT%20with%20different%20expression%20bins%0A%20%20%20%20%20%20%20%20gene_sequences%20%3D%20%5B%5B1%2C%202%2C%203%5D%2C%20%5B2%2C%203%2C%204%5D%5D%0A%20%20%20%20%20%20%20%20expr_sequences%20%3D%20%5B%5B0.5%2C%200.8%2C%200.2%5D%2C%20%5B0.9%2C%200.1%2C%200.7%5D%5D%0A%0A%20%20%20%20%20%20%20%20for%20n_bins%20in%20%5B5%2C%2010%2C%2020%5D%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20scgpt_tokenizer%20%3D%20SLAFTokenizer(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20slaf_array%3Dtokenizer.slaf_array%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20tokenizer_type%3D%22scgpt%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20vocab_size%3D2000%2C%20%20%23%20Dataset%20has%20%3C2000%20genes%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20n_expression_bins%3Dn_bins%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20start_time%20%3D%20time.time()%0A%20%20%20%20%20%20%20%20%20%20%20%20input_ids%2C%20attention_mask%20%3D%20scgpt_tokenizer.tokenize(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20gene_sequences%3Dgene_sequences%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20expr_sequences%3Dexpr_sequences%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20max_genes%3D25%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%20%20%20%20%20%20%20%20%20%20%20%20elapsed_time%20%3D%20time.time()%20-%20start_time%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%20%20%20n_expression_bins%3D%7Bn_bins%7D%3A%20%7Belapsed_time%3A.4f%7Ds%22)%0A%0A%20%20%20%20demonstrate_advanced_features()%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20%22%22%22%0A%20%20%20%20%23%23%208.%20Memory%20and%20Performance%20Optimization%0A%0A%20%20%20%20Learn%20how%20to%20optimize%20memory%20usage%20and%20performance%20for%20large-scale%20training%3A%0A%20%20%20%20%22%22%22%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(SLAFDataLoader%2C%20slaf%2C%20time)%3A%0A%20%20%20%20def%20demonstrate_memory_optimization()%3A%0A%20%20%20%20%20%20%20%20%23%20Memory%20and%20performance%20optimization%0A%20%20%20%20%20%20%20%20print(%22%F0%9F%92%BE%20Memory%20and%20Performance%20Optimization%22)%0A%20%20%20%20%20%20%20%20print(%22%3D%22%20*%2045)%0A%0A%20%20%20%20%20%20%20%20import%20gc%0A%0A%20%20%20%20%20%20%20%20import%20psutil%0A%0A%20%20%20%20%20%20%20%20def%20get_memory_usage()%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22Get%20current%20memory%20usage%20in%20MB%22%22%22%0A%20%20%20%20%20%20%20%20%20%20%20%20process%20%3D%20psutil.Process()%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20process.memory_info().rss%20%2F%201024%20%2F%201024%0A%0A%20%20%20%20%20%20%20%20print(%221.%20Memory%20usage%20comparison%3A%22)%0A%0A%20%20%20%20%20%20%20%20%23%20Baseline%20memory%0A%20%20%20%20%20%20%20%20gc.collect()%0A%20%20%20%20%20%20%20%20baseline_memory%20%3D%20get_memory_usage()%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20Baseline%20memory%3A%20%7Bbaseline_memory%3A.1f%7D%20MB%22)%0A%0A%20%20%20%20%20%20%20%20%23%20Memory%20with%20different%20batch%20sizes%0A%20%20%20%20%20%20%20%20for%20batch_size%20in%20%5B8%2C%2016%2C%2032%5D%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20gc.collect()%0A%20%20%20%20%20%20%20%20%20%20%20%20start_memory%20%3D%20get_memory_usage()%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20dataloader%20%3D%20SLAFDataLoader(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20slaf_array%3Dslaf%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20batch_size%3Dbatch_size%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20max_genes%3D100%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20vocab_size%3D2000%2C%20%20%23%20Dataset%20has%20%3C2000%20genes%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20n_epochs%3D1%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Process%20one%20batch%0A%20%20%20%20%20%20%20%20%20%20%20%20_%20%3D%20next(iter(dataloader))%0A%20%20%20%20%20%20%20%20%20%20%20%20end_memory%20%3D%20get_memory_usage()%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20print(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20f%22%20%20%20Batch%20size%20%7Bbatch_size%7D%3A%20%7Bend_memory%3A.1f%7D%20MB%20(%2B%7Bend_memory%20-%20start_memory%3A.1f%7D%20MB)%22%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20print(%22%5Cn2.%20Performance%20with%20different%20settings%3A%22)%0A%0A%20%20%20%20%20%20%20%20%23%20Test%20different%20configurations%0A%20%20%20%20%20%20%20%20configs%20%3D%20%5B%0A%20%20%20%20%20%20%20%20%20%20%20%20%7B%22batch_size%22%3A%208%2C%20%22max_genes%22%3A%2050%2C%20%22description%22%3A%20%22Small%20batches%22%7D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%7B%22batch_size%22%3A%2016%2C%20%22max_genes%22%3A%20100%2C%20%22description%22%3A%20%22Medium%20batches%22%7D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%7B%22batch_size%22%3A%2032%2C%20%22max_genes%22%3A%20200%2C%20%22description%22%3A%20%22Large%20batches%22%7D%2C%0A%20%20%20%20%20%20%20%20%5D%0A%0A%20%20%20%20%20%20%20%20for%20config%20in%20configs%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20dataloader%20%3D%20SLAFDataLoader(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20slaf_array%3Dslaf%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20**%7Bk%3A%20v%20for%20k%2C%20v%20in%20config.items()%20if%20k%20!%3D%20%22description%22%7D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20n_epochs%3D1%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20start_time%20%3D%20time.time()%0A%20%20%20%20%20%20%20%20%20%20%20%20batch_count%20%3D%200%0A%20%20%20%20%20%20%20%20%20%20%20%20for%20_%20in%20dataloader%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20batch_count%20%2B%3D%201%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20batch_count%20%3E%3D%203%3A%20%20%23%20Test%20first%203%20batches%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20break%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20elapsed_time%20%3D%20time.time()%20-%20start_time%0A%20%20%20%20%20%20%20%20%20%20%20%20print(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20f%22%20%20%20%7Bconfig%5B'description'%5D%7D%3A%20%7Belapsed_time%3A.4f%7Ds%20for%20%7Bbatch_count%7D%20batches%22%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20demonstrate_memory_optimization()%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20%22%22%22%0A%20%20%20%20%23%23%209.%20Production%20Training%20Workflow%0A%0A%20%20%20%20Complete%20example%20of%20a%20production-ready%20training%20workflow%3A%0A%20%20%20%20%22%22%22%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(SLAFDataLoader%2C%20SLAFTokenizer%2C%20slaf)%3A%0A%20%20%20%20def%20create_production_workflow()%3A%0A%20%20%20%20%20%20%20%20%23%20Production%20training%20workflow%0A%20%20%20%20%20%20%20%20print(%22%F0%9F%8F%AD%20Production%20Training%20Workflow%22)%0A%20%20%20%20%20%20%20%20print(%22%3D%22%20*%2040)%0A%0A%20%20%20%20%20%20%20%20%23%20Create%20tokenizer%0A%20%20%20%20%20%20%20%20tokenizer%20%3D%20SLAFTokenizer(%0A%20%20%20%20%20%20%20%20%20%20%20%20slaf_array%3Dslaf%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20vocab_size%3D2000%2C%20%20%23%20Dataset%20has%20%3C2000%20genes%0A%20%20%20%20%20%20%20%20%20%20%20%20n_expression_bins%3D50%2C%0A%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20print(%0A%20%20%20%20%20%20%20%20%20%20%20%20f%22%E2%9C%85%20Created%20tokenizer%20with%20%7Btokenizer.get_vocab_info()%5B'vocab_size'%5D%7D%20total%20tokens%22%0A%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20%23%20Create%20dataloaders%20(in%20production%2C%20you'd%20use%20proper%20splits)%0A%20%20%20%20%20%20%20%20train_dataloader%20%3D%20SLAFDataLoader(%0A%20%20%20%20%20%20%20%20%20%20%20%20slaf_array%3Dslaf%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20tokenizer_type%3D%22geneformer%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20batch_size%3D32%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20max_genes%3D512%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20vocab_size%3D2000%2C%20%20%23%20Dataset%20has%20%3C2000%20genes%0A%20%20%20%20%20%20%20%20%20%20%20%20n_expression_bins%3D50%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20n_epochs%3D1%2C%0A%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20val_dataloader%20%3D%20SLAFDataLoader(%0A%20%20%20%20%20%20%20%20%20%20%20%20slaf_array%3Dslaf%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20tokenizer_type%3D%22geneformer%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20batch_size%3D32%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20max_genes%3D512%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20vocab_size%3D2000%2C%20%20%23%20Dataset%20has%20%3C2000%20genes%0A%20%20%20%20%20%20%20%20%20%20%20%20n_expression_bins%3D50%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20n_epochs%3D1%2C%0A%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20print(%22%5Cn%F0%9F%93%8A%20Production%20Setup%3A%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20Batch%20size%3A%20%7Btrain_dataloader.batch_size%7D%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20Max%20genes%3A%20%7Btrain_dataloader.max_genes%7D%22)%0A%0A%20%20%20%20%20%20%20%20%23%20Test%20production%20workflow%0A%20%20%20%20%20%20%20%20print(%22%5Cn%F0%9F%A7%AA%20Testing%20production%20workflow%3A%22)%0A%0A%20%20%20%20%20%20%20%20%23%20Test%20training%20batch%0A%20%20%20%20%20%20%20%20train_batch%20%3D%20next(iter(train_dataloader))%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20Training%20batch%20shape%3A%20%7Btrain_batch%5B'input_ids'%5D.shape%7D%22)%0A%0A%20%20%20%20%20%20%20%20%23%20Test%20validation%20batch%0A%20%20%20%20%20%20%20%20val_batch%20%3D%20next(iter(val_dataloader))%0A%20%20%20%20%20%20%20%20print(f%22%20%20%20Validation%20batch%20shape%3A%20%7Bval_batch%5B'input_ids'%5D.shape%7D%22)%0A%0A%20%20%20%20%20%20%20%20return%20train_dataloader%2C%20val_dataloader%2C%20tokenizer%0A%0A%20%20%20%20create_production_workflow()%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20%22%22%22%0A%20%20%20%20%23%23%2010.%20Best%20Practices%20for%20ML%20Training%0A%0A%20%20%20%20Key%20best%20practices%20for%20using%20SLAF%20in%20ML%20training%3A%0A%20%20%20%20%22%22%22%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_()%3A%0A%20%20%20%20def%20show_best_practices()%3A%0A%20%20%20%20%20%20%20%20%23%20Best%20practices%20for%20ML%20training%0A%20%20%20%20%20%20%20%20print(%22%F0%9F%92%A1%20Best%20Practices%20for%20ML%20Training%22)%0A%20%20%20%20%20%20%20%20print(%22%3D%22%20*%2040)%0A%0A%20%20%20%20%20%20%20%20print(%221.%20Tokenizer%20Configuration%3A%22)%0A%20%20%20%20%20%20%20%20print(%22%20%20%20%E2%9C%85%20Choose%20appropriate%20vocab_size%20based%20on%20your%20dataset%22)%0A%20%20%20%20%20%20%20%20print(%22%20%20%20%E2%9C%85%20Use%20n_expression_bins%3D50%20for%20fine-grained%20expression%20modeling%22)%0A%20%20%20%20%20%20%20%20print(%22%20%20%20%E2%9C%85%20Use%20the%20correct%20tokenizer_type%20for%20your%20model%20architecture%22)%0A%0A%20%20%20%20%20%20%20%20print(%22%5Cn2.%20DataLoader%20Configuration%3A%22)%0A%20%20%20%20%20%20%20%20print(%22%20%20%20%E2%9C%85%20Start%20with%20small%20batch_size%20and%20increase%20gradually%22)%0A%20%20%20%20%20%20%20%20print(%22%20%20%20%E2%9C%85%20Use%20max_genes%20appropriate%20for%20your%20model%20architecture%22)%0A%20%20%20%20%20%20%20%20print(%22%20%20%20%E2%9C%85%20Set%20n_epochs%20for%20multi-epoch%20training%20on%20small%20datasets%22)%0A%0A%20%20%20%20%20%20%20%20print(%22%5Cn3.%20Performance%20Optimization%3A%22)%0A%20%20%20%20%20%20%20%20print(%22%20%20%20%E2%9C%85%20Fragment-based%20processing%20is%20much%20faster%20than%20SQL%22)%0A%20%20%20%20%20%20%20%20print(%22%20%20%20%E2%9C%85%20Use%20async%20prefetching%20to%20minimize%20GPU%20idle%20time%22)%0A%20%20%20%20%20%20%20%20print(%22%20%20%20%E2%9C%85%20Leverage%20device%20optimization%20for%20automatic%20tensor%20transfer%22)%0A%20%20%20%20%20%20%20%20print(%22%20%20%20%E2%9C%85%20Monitor%20memory%20usage%20during%20training%22)%0A%0A%20%20%20%20%20%20%20%20print(%22%5Cn4.%20Training%20Workflow%3A%22)%0A%20%20%20%20%20%20%20%20print(%22%20%20%20%E2%9C%85%20Create%20separate%20train%2Fval%2Ftest%20splits%22)%0A%20%20%20%20%20%20%20%20print(%22%20%20%20%E2%9C%85%20Use%20consistent%20tokenizer%20across%20splits%22)%0A%20%20%20%20%20%20%20%20print(%22%20%20%20%E2%9C%85%20Implement%20proper%20error%20handling%22)%0A%20%20%20%20%20%20%20%20print(%22%20%20%20%E2%9C%85%20Use%20streaming%20datasets%20for%20large%20datasets%22)%0A%0A%20%20%20%20%20%20%20%20print(%22%5Cn5.%20Production%20Considerations%3A%22)%0A%20%20%20%20%20%20%20%20print(%22%20%20%20%E2%9C%85%20Use%20appropriate%20batch%20sizes%20for%20your%20hardware%22)%0A%20%20%20%20%20%20%20%20print(%22%20%20%20%E2%9C%85%20Implement%20checkpointing%20for%20long%20training%20runs%22)%0A%20%20%20%20%20%20%20%20print(%22%20%20%20%E2%9C%85%20Monitor%20tokenization%20throughput%22)%0A%20%20%20%20%20%20%20%20print(%22%20%20%20%E2%9C%85%20Consider%20distributed%20training%20for%20large%20datasets%22)%0A%0A%20%20%20%20show_best_practices()%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(%0A%20%20%20%20%20%20%20%20%22%22%22%0A%20%20%20%20%23%23%20Summary%0A%0A%20%20%20%20**What%20you've%20learned%20about%20SLAF%20ML%20Training%3A**%0A%0A%20%20%20%201.%20**Streaming%20DataLoader**%3A%20Async%20prefetching%20with%20PyTorch%20compatibility%0A%20%20%20%202.%20**Tokenization%20Strategies**%3A%20Geneformer%20and%20scGPT%20formats%20with%20optimized%20processing%0A%20%20%20%203.%20**Memory%20Efficiency**%3A%20Streaming%20datasets%20for%20large-scale%20training%0A%20%20%20%204.%20**Production%20Workflow**%3A%20Complete%20training%20pipeline%20setup%0A%20%20%20%205.%20**Best%20Practices**%3A%20Guidelines%20for%20optimal%20ML%20training%20performance%0A%0A%20%20%20%20**Key%20Performance%20Improvements%3A**%0A%20%20%20%20-%20Fragment%20processing%20for%20high%20throughput%0A%20%20%20%20-%20Streaming%20datasets%20with%20async%20prefetching%0A%20%20%20%20-%20Automatic%20device%20optimization%0A%20%20%20%20-%20Memory-efficient%20processing%20for%20large%20datasets%0A%20%20%20%20%22%22%22%0A%20%20%20%20)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_()%3A%0A%20%20%20%20return%0A%0A%0Aif%20__name__%20%3D%3D%20%22__main__%22%3A%0A%20%20%20%20app.run()%0A
</marimo-code>

<marimo-code-hash hidden="">acb85952033a5138d36cf39bf51793e38e6b15e9004a36e546cc2960eeae38eb</marimo-code-hash>
</body>
</html>
